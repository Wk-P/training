{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openpyxl import Workbook, load_workbook  # type: ignore\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def to_excel(\n",
    "    data, filename, sheet_style, result_dir_path, new_sheet=False, sheet_name=\"Sheet1\"\n",
    "):\n",
    "\n",
    "    if not os.path.exists(result_dir_path):\n",
    "        os.makedirs(result_dir_path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(result_dir_path, f\"{filename}.xlsx\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        workbook = load_workbook(file_path)\n",
    "        if new_sheet:\n",
    "            sheet = workbook.create_sheet(title=sheet_name)\n",
    "\n",
    "        else:\n",
    "            sheet = workbook.active\n",
    "    else:\n",
    "        workbook = Workbook()\n",
    "        default_sheet = workbook.active\n",
    "        workbook.remove(default_sheet)\n",
    "        sheet = workbook.create_sheet(title=sheet_name)\n",
    "        \n",
    "    if sheet_style:\n",
    "        sheet.append(sheet_style)\n",
    "\n",
    "\n",
    "    if new_sheet:\n",
    "        print(data)\n",
    "    # write data into file\n",
    "    for row in data:\n",
    "        sheet.append(row)\n",
    "\n",
    "    workbook.save(filename=f\"{result_dir_path}\\\\{filename}.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# read input dataset\n",
    "filename_prefix = (\n",
    "    \"clientv_single_worker_node-L1-RB150-DTTueSep31817402024\"\n",
    ")\n",
    "\n",
    "\n",
    "dataset_read_filename = filename_prefix\n",
    "training_data_dir = Path.cwd().parent / \"training_data\"\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "file_path = f\"{training_data_dir}\\\\{dataset_read_filename}.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "# set result output filename and path\n",
    "result_suffix = \"result\"\n",
    "\n",
    "result_dir_path = Path.cwd().parent / \"results\" / \"result_processTime_waitTasks_v1\"\n",
    "\n",
    "if not os.path.exists(result_dir_path):\n",
    "    os.makedirs(result_dir_path)\n",
    "\n",
    "version_index = len([_ for _ in Path(result_dir_path).iterdir() if _.is_file()])\n",
    "version = f\"_v{version_index}\"\n",
    "\n",
    "result_name = \"processTime#waitTasks\" + version\n",
    "result_output_filename = f\"{filename_prefix}{result_name}{result_suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_excel(filename)\n",
    "    columns = df.columns.to_list()\n",
    "    data_dict = {col: df[col].to_list() for col in columns}\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def data_preprocess(filepath):\n",
    "    data = read_data(filepath)\n",
    "    # TODO more...\n",
    "\n",
    "    # to numpy\n",
    "    for key in data.keys():\n",
    "        data[key] = np.array(data[key])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_preprocess(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Style View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# # dataset is a dictionary\n",
    "\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "import cupy as cp                                      # type: ignore\n",
    "\n",
    "y = cp.array(dataset.get(\"worker_wait_time\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strandard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler       # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler         # type: ignore\n",
    "from sklearn.preprocessing import PowerTransformer     # type: ignore\n",
    "import numpy as np                                     # type: ignore\n",
    "\n",
    "_X = [dataset.get(\"request_num\"), dataset.get(\n",
    "    \"jobs_on_worker_node\")]\n",
    "\n",
    "for i in range(len(_X)):\n",
    "    _X[i] = np.array(_X[i]).reshape(-1, 1)\n",
    "    \n",
    "\n",
    "# _scaler = \"normalization\"\n",
    "_scaler = None\n",
    "\n",
    "if _scaler == \"standard\":\n",
    "    X_scaler = StandardScaler()\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "elif _scaler == \"normalization\":\n",
    "    X_scaler = MinMaxScaler()\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "elif _scaler == \"log\":\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = np.log1p(_X[i])\n",
    "elif _scaler == \"power\":\n",
    "    X_scaler = PowerTransformer(method='yeo-johnson')\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "for i in range(len(_X)):\n",
    "    _X[i] = _X[i].reshape(-1)\n",
    "\n",
    "X = cp.asarray(np.array(\n",
    "    _X\n",
    ").T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter combinations: 126\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the parameter ranges\n",
    "params = {\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"n_estimators\": [100, 200, 400, 1000, 1500, 2000, 3000],\n",
    "    \"min_child_weight\": [1],\n",
    "    \"subsample\": [0.7, 1],\n",
    "    \"colsample_bytree\": [0.7, 0.9, 1],\n",
    "    \"reg_alpha\": [0.1],\n",
    "    \"reg_lambda\": [0.1],\n",
    "}\n",
    "\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "parameter_combinations = [\n",
    "    dict(zip(params.keys(), combination))\n",
    "    for combination in itertools.product(*params.values())\n",
    "]\n",
    "\n",
    "# Print the number of parameter combinations and a few examples\n",
    "print(f\"Number of parameter combinations: {len(parameter_combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor  # type: ignore\n",
    "import xgboost  # type: ignore\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # type: ignore\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# Create the XGBoost regressor model\n",
    "def create_model(params):\n",
    "    # if use gpu to add these two params\n",
    "    # - tree_method=\"hist\",\n",
    "    # - device=\"cuda\",\n",
    "    \n",
    "    return XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        subsample=params[\"subsample\"],\n",
    "        colsample_bytree=params[\"colsample_bytree\"],\n",
    "        reg_alpha=params[\"reg_alpha\"],\n",
    "        reg_lambda=params[\"reg_lambda\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(\n",
    "    params, X_train, y_train, X_test: np.array, y_test: np.array\n",
    ") -> Tuple[np.float64, xgboost.Booster]:\n",
    "\n",
    "    model = create_model(params)\n",
    "\n",
    "    # Convert CuPy arrays to NumPy arrays\n",
    "\n",
    "    model.fit(X_train, y_train, verbose=True)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # typecasting  cp -> np\n",
    "    y_test_np = cp.asnumpy(y_test)\n",
    "    X_test_np = cp.asnumpy(X_test)\n",
    "    predictions_np = cp.asnumpy(predictions)\n",
    "\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = float(mean_squared_error(y_test_np, predictions_np))\n",
    "    mae = float(mean_absolute_error(y_test_np, predictions_np))\n",
    "    avg = float(np.mean(y_test_np))\n",
    "    avg_acc = 100 * (avg - mae) / avg\n",
    "\n",
    "    # calculate diffirence and accuracy\n",
    "    data_list = list()\n",
    "    for i in range(len(y_test_np)):\n",
    "        acc = 0\n",
    "        diff = abs(y_test_np[i] - predictions_np[i])\n",
    "        if predictions[i] < 0:\n",
    "            acc = 0\n",
    "        else:\n",
    "            rate = diff / y_test_np[i]\n",
    "            if rate < 1 and rate >= 0:\n",
    "                acc = 1 - rate\n",
    "            if rate > 1:\n",
    "                acc = 0\n",
    "        data_list.append(\n",
    "            [\n",
    "                float(X_test_np[i][0]),\n",
    "                float(X_test_np[i][1]),\n",
    "                float(y_test_np[i]),\n",
    "                float(predictions_np[i]),\n",
    "                float(diff),\n",
    "                float(round(acc, 5)),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    results_tuple = {\"mse\": mse, \"mae\": mae, \"avg\": avg, \"avg_acc\": avg_acc, \"model\": model, \"data_list\": data_list}\n",
    "    filtered_results = {k: v for k, v in results_tuple.items() if k != \"model\" and k != \"data_list\"}\n",
    "    print(filtered_results, f'\\n{params}', '\\n')\n",
    "    return results_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\model_fit\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:05:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cpu, while the input data is on: cuda:0.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 3310.462635246479, 'mae': 48.271174105008434, 'avg': 166.8632319053014, 'avg_acc': 71.07141366385412} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 71.07141366385412\n",
      "{'mse': 4411.698726113945, 'mae': 58.54437648455301, 'avg': 195.12054869333903, 'avg_acc': 69.99579138301615} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 71.07141366385412\n",
      "{'mse': 2011.4119410070186, 'mae': 39.64346466859182, 'avg': 184.0957535982132, 'avg_acc': 78.46584514104914} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 78.46584514104914\n",
      "{'mse': 4677.07447469602, 'mae': 60.15437638759613, 'avg': 149.01106186707815, 'avg_acc': 59.63093233893237} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 78.46584514104914\n",
      "{'mse': 3647.2971523838382, 'mae': 51.09884270032246, 'avg': 182.13354137738546, 'avg_acc': 71.94429849994279} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 78.46584514104914\n",
      "{'mse': 1631.0696296665856, 'mae': 35.197768688201904, 'avg': 165.73664814631144, 'avg_acc': 78.76283303549768} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 78.76283303549768\n",
      "{'mse': 1827.5341507089604, 'mae': 37.383872056007384, 'avg': 178.40865304470063, 'avg_acc': 79.0459311148766} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 79.0459311148766\n",
      "{'mse': 1911.8473184684224, 'mae': 38.10697282950083, 'avg': 178.13062263329823, 'avg_acc': 78.60728701995936} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 79.0459311148766\n",
      "{'mse': 260.1762855173089, 'mae': 13.565737406412756, 'avg': 169.17564771970112, 'avg_acc': 91.98127059700155} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 91.98127059700155\n",
      "{'mse': 1979.5796982639467, 'mae': 38.275415110588064, 'avg': 197.26160606543223, 'avg_acc': 80.59662198132362} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 91.98127059700155\n",
      "{'mse': 1868.3118395471024, 'mae': 37.93570040067036, 'avg': 193.57438549995422, 'avg_acc': 80.40252055937466} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 91.98127059700155\n",
      "{'mse': 220.02619744252007, 'mae': 12.13015473683675, 'avg': 162.65347771644593, 'avg_acc': 92.54233299703357} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 92.54233299703357\n",
      "{'mse': 306.5680482816312, 'mae': 15.166837970415747, 'avg': 167.71978415648144, 'avg_acc': 90.95703703251539} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 92.54233299703357\n",
      "{'mse': 317.0078385426912, 'mae': 14.66942462921143, 'avg': 178.45709015528362, 'avg_acc': 91.77985889131841} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 92.54233299703357\n",
      "{'mse': 21.288282963534975, 'mae': 4.153473957379658, 'avg': 167.56723250548046, 'avg_acc': 97.52130897235902} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 97.52130897235902\n",
      "{'mse': 314.4757900581765, 'mae': 16.059395710627246, 'avg': 166.58763243357342, 'avg_acc': 90.35979113453641} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 97.52130897235902\n",
      "{'mse': 272.7491811200879, 'mae': 12.727299372355132, 'avg': 216.17137490908306, 'avg_acc': 94.1124030053896} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 97.52130897235902\n",
      "{'mse': 21.939588823973995, 'mae': 3.5735979874928736, 'avg': 186.787908744812, 'avg_acc': 98.08681514156514} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.08681514156514\n",
      "{'mse': 16.544769354802146, 'mae': 3.0545065085093275, 'avg': 147.06330444018047, 'avg_acc': 97.92299886083971} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.08681514156514\n",
      "{'mse': 27.352473412906832, 'mae': 4.247192041079205, 'avg': 185.61986900965374, 'avg_acc': 97.71188716825442} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.08681514156514\n",
      "{'mse': 22.359591060568103, 'mae': 3.640746982892354, 'avg': 192.90638840198517, 'avg_acc': 98.11268718830316} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.11268718830316\n",
      "{'mse': 22.913065151809448, 'mae': 3.4847720781962077, 'avg': 158.9111935456594, 'avg_acc': 97.80709464170316} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.11268718830316\n",
      "{'mse': 34.42152765367305, 'mae': 4.642417216300958, 'avg': 195.79084712664286, 'avg_acc': 97.62888956024683} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.11268718830316\n",
      "{'mse': 26.198829650892183, 'mae': 3.727255583802862, 'avg': 172.6296223640442, 'avg_acc': 97.84089455056399} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.11268718830316\n",
      "{'mse': 12.323800814769845, 'mae': 2.652082510789234, 'avg': 164.60955591996512, 'avg_acc': 98.38886479222464} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.38886479222464\n",
      "{'mse': 15.750544799239968, 'mae': 2.8614339590072624, 'avg': 163.5659634033839, 'avg_acc': 98.25059327780167} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.38886479222464\n",
      "{'mse': 27.27838241971351, 'mae': 4.351214066644514, 'avg': 171.12230381965637, 'avg_acc': 97.45724901458189} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.38886479222464\n",
      "{'mse': 16.572720027046913, 'mae': 2.7027913024028236, 'avg': 166.04719167550405, 'avg_acc': 98.372275209758} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.38886479222464\n",
      "{'mse': 32.41949487456248, 'mae': 4.59867859681448, 'avg': 180.77190124988556, 'avg_acc': 97.45608771882219} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.38886479222464\n",
      "{'mse': 19.487764411984312, 'mae': 3.229015038907526, 'avg': 201.45744655132293, 'avg_acc': 98.39717265646723} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.39717265646723\n",
      "{'mse': 26.517566071712665, 'mae': 4.099531165758763, 'avg': 182.42619490623474, 'avg_acc': 97.75277274852665} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.39717265646723\n",
      "{'mse': 25.256721068986394, 'mae': 3.9815443774064367, 'avg': 186.16574122905732, 'avg_acc': 97.8612905085971} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.39717265646723\n",
      "{'mse': 43.987908873444304, 'mae': 5.720674624045682, 'avg': 200.38001494407655, 'avg_acc': 97.14508723554981} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.39717265646723\n",
      "{'mse': 29.85088991232181, 'mae': 4.234137535095224, 'avg': 183.9276392141978, 'avg_acc': 97.69793297343189} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.39717265646723\n",
      "{'mse': 20.313170452787116, 'mae': 3.0055618047714243, 'avg': 193.01977291901906, 'avg_acc': 98.44287361894659} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.44287361894659\n",
      "{'mse': 34.627536679907124, 'mae': 4.569078437983984, 'avg': 188.38240579764047, 'avg_acc': 97.57457262601685} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.44287361894659\n",
      "{'mse': 24.253906759760106, 'mae': 4.000407671928404, 'avg': 169.98035225073497, 'avg_acc': 97.64654701619428} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.44287361894659\n",
      "{'mse': 23.28445502573915, 'mae': 3.6901204029719064, 'avg': 195.75019093354544, 'avg_acc': 98.11488285892673} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.44287361894659\n",
      "{'mse': 16.32668718692359, 'mae': 2.8334924310445797, 'avg': 167.76913803418478, 'avg_acc': 98.31107648030758} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.44287361894659\n",
      "{'mse': 33.478732568769566, 'mae': 4.643161745866148, 'avg': 182.79723230202993, 'avg_acc': 97.45993870509243} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.44287361894659\n",
      "{'mse': 14.764187942653896, 'mae': 2.412517430384952, 'avg': 184.6493721485138, 'avg_acc': 98.69346025804812} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 24.53456762308759, 'mae': 3.5937800926466803, 'avg': 219.3458352883657, 'avg_acc': 98.361591826933} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 4848.242478057655, 'mae': 62.1394003868103, 'avg': 168.1345411300659, 'avg_acc': 63.04185923418296} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 5515.642971643502, 'mae': 69.69264264901479, 'avg': 154.29902301629383, 'avg_acc': 54.832738868569955} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1775.8323037210635, 'mae': 36.61504219373067, 'avg': 152.50950808525084, 'avg_acc': 75.99163314246393} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 3576.719375368895, 'mae': 50.41119956970215, 'avg': 181.4736020565033, 'avg_acc': 72.22119415803175} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 4938.671769660427, 'mae': 60.518334698677066, 'avg': 175.64452051321666, 'avg_acc': 65.54499137129459} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1397.8411507990227, 'mae': 32.940834418932596, 'avg': 183.0046380440394, 'avg_acc': 82.00000023441727} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 2135.8411832506285, 'mae': 40.64546140829722, 'avg': 172.50223316351574, 'avg_acc': 76.43771871070841} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1304.7671817701498, 'mae': 30.19924612840016, 'avg': 182.3287912607193, 'avg_acc': 83.43692956028156} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 158.2525003622185, 'mae': 10.282899355888366, 'avg': 172.30745928287507, 'avg_acc': 94.03223783886973} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1947.2435194052055, 'mae': 39.67872607707977, 'avg': 166.16417920589447, 'avg_acc': 76.1207702726869} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1767.049924466612, 'mae': 35.70192796389261, 'avg': 150.2269510746002, 'avg_acc': 76.23467180255584} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 277.34680449740944, 'mae': 14.250344141324357, 'avg': 171.487588651975, 'avg_acc': 91.6901600556967} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 292.6236715212396, 'mae': 13.789816061655689, 'avg': 175.37485315004986, 'avg_acc': 92.13694790674624} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 303.67539131379624, 'mae': 15.031081581115728, 'avg': 178.67836867968242, 'avg_acc': 91.58763218391476} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 43.096192521417635, 'mae': 5.371004573504136, 'avg': 187.51496460437775, 'avg_acc': 97.13569283132364} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 316.3796472201006, 'mae': 15.769054174423212, 'avg': 151.4761619726817, 'avg_acc': 89.58974536384997} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 325.49554863554437, 'mae': 15.242756724357609, 'avg': 169.09790071646373, 'avg_acc': 90.98583917377186} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 34.98057117663393, 'mae': 4.507506585121162, 'avg': 197.92071047623952, 'avg_acc': 97.7225695207565} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 24.236849636826985, 'mae': 3.8948441584905065, 'avg': 159.57252592245737, 'avg_acc': 97.5592012873299} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 21.227883865362596, 'mae': 3.7057805220286046, 'avg': 170.0891276995341, 'avg_acc': 97.82127136981092} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 33.88382062363077, 'mae': 4.704397773742679, 'avg': 189.19505887031556, 'avg_acc': 97.51346689399149} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 18.39221320710737, 'mae': 3.3387659788131705, 'avg': 155.93581920464834, 'avg_acc': 97.85888451040783} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 38.52720422029781, 'mae': 4.985398379961654, 'avg': 185.9024740298589, 'avg_acc': 97.31827217148228} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 20.75756462549855, 'mae': 3.1903770685195982, 'avg': 189.29776771068572, 'avg_acc': 98.3146250972195} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 22.510796605612473, 'mae': 3.5949392477671354, 'avg': 182.90537802378336, 'avg_acc': 98.03453606088078} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 18.582312176597565, 'mae': 3.092217513422165, 'avg': 185.91365800698597, 'avg_acc': 98.3367453760143} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 29.600821185759134, 'mae': 4.133275635664659, 'avg': 177.69773807525635, 'avg_acc': 97.67398522883045} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 33.178110091409984, 'mae': 4.457578079899158, 'avg': 154.93713375727336, 'avg_acc': 97.12297628605776} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 36.92677181610883, 'mae': 4.660795814792317, 'avg': 188.79006095727286, 'avg_acc': 97.53122818481046} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 26.696094640566866, 'mae': 3.447712930043549, 'avg': 169.84769538243611, 'avg_acc': 97.97011497725623} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 30.511457591542463, 'mae': 4.601035505533223, 'avg': 163.0187997897466, 'avg_acc': 97.17760435516186} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 22.942222525685356, 'mae': 3.389648739496865, 'avg': 219.01116797129313, 'avg_acc': 98.45229411317456} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 21.14583378881029, 'mae': 3.2461819797754328, 'avg': 192.40500252246858, 'avg_acc': 98.31283909606438} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 25.200910732399656, 'mae': 3.7834749539693346, 'avg': 203.47818115552266, 'avg_acc': 98.14059918735092} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 43.545295091405166, 'mae': 5.752434392770139, 'avg': 181.7325126806895, 'avg_acc': 96.83466964280774} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 28.778030896474753, 'mae': 3.6192270393172863, 'avg': 176.2942348162333, 'avg_acc': 97.94705309388596} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 29.560724841269803, 'mae': 4.2654098689556115, 'avg': 192.58570784727732, 'avg_acc': 97.78518877821499} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 24.15942270189322, 'mae': 3.644369411468512, 'avg': 194.6150774637858, 'avg_acc': 98.12739616120098} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 25.08076570418803, 'mae': 3.6675961653391567, 'avg': 159.58488731384278, 'avg_acc': 97.70178979534172} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 40.76129650710301, 'mae': 4.479573901494339, 'avg': 202.01570463180542, 'avg_acc': 97.78256155398472} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 27.81575628433571, 'mae': 3.8815960963567013, 'avg': 216.71600964069367, 'avg_acc': 98.20890200830468} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 28.13733877260916, 'mae': 3.9149706204732286, 'avg': 188.88480423291523, 'avg_acc': 97.92732367414497} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 3505.7387744748708, 'mae': 52.815610313415526, 'avg': 184.22095375061036, 'avg_acc': 71.3302915666614} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 3998.271878099628, 'mae': 53.196040614446, 'avg': 201.03064629236857, 'avg_acc': 73.53834273751455} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1752.7936497818605, 'mae': 36.50788947741191, 'avg': 162.23792621294658, 'avg_acc': 77.49731500543639} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 4655.261107425792, 'mae': 59.9608434120814, 'avg': 155.64412508805592, 'avg_acc': 61.47567832826426} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 4789.668497728219, 'mae': 62.92745700677236, 'avg': 211.74697269598644, 'avg_acc': 70.28176780731604} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 2074.250746133924, 'mae': 40.4629321972529, 'avg': 202.96074863274893, 'avg_acc': 80.06366626560424} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 2239.4982288488204, 'mae': 44.00772441228231, 'avg': 164.07405848503112, 'avg_acc': 73.17813381431213} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1431.1863019878294, 'mae': 32.399664521217346, 'avg': 175.98038187821706, 'avg_acc': 81.58904749755644} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 206.6564363253743, 'mae': 12.983720167477937, 'avg': 173.57694084644316, 'avg_acc': 92.51990494580491} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1680.1046729918935, 'mae': 35.31628287633259, 'avg': 194.03773584365845, 'avg_acc': 81.79927078473648} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 1640.8369352468026, 'mae': 34.03000884850819, 'avg': 174.88212786515552, 'avg_acc': 80.54117406739967} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 299.36711114436997, 'mae': 15.50982644557953, 'avg': 165.47615338166554, 'avg_acc': 90.62715314042465} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 200, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 336.6624899286147, 'mae': 15.117022188504537, 'avg': 150.02224813302357, 'avg_acc': 89.92347976608083} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 332.2974326096384, 'mae': 15.47851488590241, 'avg': 218.8366150299708, 'avg_acc': 92.92690810274938} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 24.732779193166014, 'mae': 3.9609038273493438, 'avg': 173.44483746687573, 'avg_acc': 97.71633224418927} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 291.2360570841775, 'mae': 14.962947257359833, 'avg': 162.2588970184326, 'avg_acc': 90.77835019693246} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 331.54129446722277, 'mae': 15.748696645100903, 'avg': 185.54108459154764, 'avg_acc': 91.51201650040461} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 26.51376206385662, 'mae': 4.046614583333328, 'avg': 199.44767429033917, 'avg_acc': 97.97108961148245} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 400, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 24.950455952188406, 'mae': 4.154282291730251, 'avg': 176.3755174557368, 'avg_acc': 97.64463778666287} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 20.05875726189548, 'mae': 3.403605484962468, 'avg': 196.76495082378386, 'avg_acc': 98.27021760190888} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 24.742527758088922, 'mae': 3.2552971144517318, 'avg': 181.18217344284056, 'avg_acc': 98.2033016534716} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 14.230524510506806, 'mae': 2.509924658139545, 'avg': 189.35446191628773, 'avg_acc': 98.67448348840644} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 23.598888792470387, 'mae': 3.547977757453918, 'avg': 163.45949516296386, 'avg_acc': 97.82944529841066} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 31.195898531823232, 'mae': 4.380754462877926, 'avg': 193.87827438513438, 'avg_acc': 97.74046139167937} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 24.865920086556123, 'mae': 3.7688688675562507, 'avg': 206.25630147457122, 'avg_acc': 98.17272546796787} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 16.628788604556817, 'mae': 2.8908267100652063, 'avg': 187.31538299719492, 'avg_acc': 98.4567061904849} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 30.38433479652106, 'mae': 4.061950079600013, 'avg': 185.26211172739664, 'avg_acc': 97.8074577463648} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 23.185485591105657, 'mae': 3.3570480724175753, 'avg': 170.96229209105175, 'avg_acc': 98.0363809870836} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 22.21841696575263, 'mae': 3.574850765864061, 'avg': 193.65220917065938, 'avg_acc': 98.15398399988628} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 34.39503888054018, 'mae': 4.734396550059327, 'avg': 130.89793208440148, 'avg_acc': 96.38313877486877} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 22.479138648890864, 'mae': 3.3777894655863387, 'avg': 195.20447516441345, 'avg_acc': 98.26961473975359} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.69346025804812\n",
      "{'mse': 13.023713823954322, 'mae': 2.3201822200169198, 'avg': 200.77148072719575, 'avg_acc': 98.8443666343381} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 31.839514888330395, 'mae': 4.086376661558953, 'avg': 163.58637699286143, 'avg_acc': 97.50200674611355} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 32.332745324444865, 'mae': 4.169020493825273, 'avg': 177.45438917477927, 'avg_acc': 97.65065236582055} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 29.603994817524228, 'mae': 4.000409968694057, 'avg': 184.6301554997762, 'avg_acc': 97.83328462359503} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 47.171630877667866, 'mae': 5.772752266749737, 'avg': 154.86582287947337, 'avg_acc': 96.27241688358673} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 42.46469250387055, 'mae': 5.228071498870853, 'avg': 224.39886627197265, 'avg_acc': 97.67018809598869} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 35.04180894634054, 'mae': 4.220802762111025, 'avg': 178.9394533554713, 'avg_acc': 97.6412117713771} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 22.556041339434646, 'mae': 3.3553981622060123, 'avg': 195.8214003562927, 'avg_acc': 98.28650078280468} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 32.63388699060661, 'mae': 4.3914296825726815, 'avg': 162.7218005100886, 'avg_acc': 97.30126530753301} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 38.71659404416744, 'mae': 4.891300241152441, 'avg': 174.2131584405899, 'avg_acc': 97.19234741799342} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "{'mse': 35.41294172316793, 'mae': 3.779831832647321, 'avg': 169.1524072964986, 'avg_acc': 97.76542829448366} \n",
      "{'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 3000, 'min_child_weight': 1, 'subsample': 1, 'colsample_bytree': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1} \n",
      "\n",
      "Best acc 98.8443666343381\n",
      "Best Parameters: {'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Best MSE: 12.323800814769845\n",
      "Best MAE: 2.652082510789234\n",
      "Average: 164.60955591996512\n",
      "Average accuracy: 98.38886479222464\n",
      "Results saved finished.\n",
      "[[3, 0.01, 1500, 1, 0.7, 0.7, 0.1, 0.1]]\n",
      "[[7, 0.01, 2000, 1, 0.7, 0.9, 0.1, 0.1]]\n",
      "[[7, 0.01, 2000, 1, 0.7, 0.9, 0.1, 0.1]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to track the best parameters\n",
    "best_params = None\n",
    "best_result = None\n",
    "\n",
    "# results param\n",
    "best_mse = float(\"inf\")\n",
    "best_avg_acc = float(-1)\n",
    "best_mae = float(\"inf\")\n",
    "\n",
    "# result params tuple\n",
    "best_avg_acc_params = None\n",
    "best_mae_params = None\n",
    "\n",
    "\n",
    "# control sheet style of excel written\n",
    "first_write = True\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate each parameter combination\n",
    "for params in parameter_combinations:\n",
    "\n",
    "    # split dataset to train dataset and test dataset for every params group\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=None\n",
    "    )\n",
    "    results_tuple = evaluate_model(params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    filtered_results = {\n",
    "        k: v for k, v in results_tuple.items() if k != \"model\" and k != \"data_list\"\n",
    "    }\n",
    "\n",
    "    # update best model\n",
    "    if results_tuple['mse'] < best_mse:\n",
    "        best_mse = results_tuple[\"mse\"]\n",
    "        best_params = params\n",
    "        best_model = results_tuple[\"model\"]\n",
    "        best_result = filtered_results\n",
    "\n",
    "    # write result into excel file\n",
    "    sheet_style = [\"num\", \"jobs\", \"processed_time\", \"X_test\", \"prediction\", \"difference\", \"accuracy\"]\n",
    "    avg_acc = results_tuple[\"avg_acc\"]\n",
    "    data_list = results_tuple['data_list']\n",
    "\n",
    "    if best_avg_acc < results_tuple['avg_acc']:\n",
    "        best_avg_acc = results_tuple[\"avg_acc\"]\n",
    "        best_acc_params = params\n",
    "\n",
    "    if best_mae > results_tuple['mae']:\n",
    "        best_mae = results_tuple[\"mae\"]\n",
    "        best_mae_params = params\n",
    "\n",
    "    if first_write:\n",
    "        # sheet 1\n",
    "        to_excel(\n",
    "            data=data_list,\n",
    "            filename=result_output_filename,\n",
    "            sheet_style=sheet_style,\n",
    "            result_dir_path=result_dir_path,\n",
    "            new_sheet=False,\n",
    "        )\n",
    "        first_write = False\n",
    "    else:\n",
    "        to_excel(\n",
    "            data=data_list,\n",
    "            filename=result_output_filename,\n",
    "            sheet_style=None,\n",
    "            result_dir_path=result_dir_path,\n",
    "            new_sheet=False,\n",
    "        )\n",
    "    print(f\"Best acc {best_avg_acc}\")\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best MSE:\", best_mse)\n",
    "print(\"Best MAE:\", best_result[\"mae\"])\n",
    "print(\"Average:\", best_result[\"avg\"])\n",
    "print(\"Average accuracy:\", best_result[\"avg_acc\"])\n",
    "print(\"Results saved finished.\")\n",
    "\n",
    "params_keys_list = list(best_params.keys())\n",
    "params_values_list = list(best_params.values())\n",
    "\n",
    "# best mse params\n",
    "to_excel(\n",
    "    data=[params_values_list],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=params_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best mse params\",\n",
    ")\n",
    "\n",
    "\n",
    "result_keys_list = list(filtered_results.keys())\n",
    "\n",
    "# avg_acc sheet\n",
    "to_excel(\n",
    "    data=[list(best_acc_params.values())],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=result_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best avg acc params\",\n",
    ")\n",
    "\n",
    "\n",
    "# mae sheet\n",
    "to_excel(\n",
    "    data=[list(best_mae_params.values())],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=result_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best mae params\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# model_file = \"xboost_tasks_time\" + \".json\"\n",
    "# model_path = str(Path.cwd() / \"modelsfile\" / model_file)\n",
    "# best_model.save_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
