{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openpyxl import Workbook, load_workbook  # type: ignore\n",
    "import os\n",
    "\n",
    "\n",
    "def to_excel(\n",
    "    data, filename, sheet_style, result_dir_path, new_sheet=False, sheet_name=\"Sheet1\"\n",
    "):\n",
    "\n",
    "    if not os.path.exists(result_dir_path):\n",
    "        os.makedirs(result_dir_path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(result_dir_path, f\"{filename}.xlsx\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        workbook = load_workbook(file_path)\n",
    "        if new_sheet:\n",
    "            sheet = workbook.create_sheet(title=sheet_name)\n",
    "\n",
    "        else:\n",
    "            sheet = workbook.active\n",
    "    else:\n",
    "        workbook = Workbook()\n",
    "        default_sheet = workbook.active\n",
    "        workbook.remove(default_sheet)\n",
    "        sheet = workbook.create_sheet(title=sheet_name)\n",
    "        \n",
    "    if sheet_style:\n",
    "        sheet.append(sheet_style)\n",
    "\n",
    "\n",
    "    if new_sheet:\n",
    "        print(data)\n",
    "    # write data into file\n",
    "    for row in data:\n",
    "        sheet.append(row)\n",
    "\n",
    "    workbook.save(filename=f\"{result_dir_path}\\\\{filename}.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# read input dataset\n",
    "filename_prefix = (\n",
    "    \"RANDclient_test-DTWedSep251926542024\"\n",
    ")\n",
    "\n",
    "\n",
    "dataset_read_filename = filename_prefix\n",
    "training_data_dir = Path.cwd().parent / \"training_data\"\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "file_path = f\"{training_data_dir}\\\\{dataset_read_filename}.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "# set result output filename and path\n",
    "result_suffix = \"result\"\n",
    "\n",
    "result_dir_path = Path.cwd().parent / \"results\" / \"result_processTime_waitTasks_v4\"\n",
    "\n",
    "if not os.path.exists(result_dir_path):\n",
    "    os.makedirs(result_dir_path)\n",
    "\n",
    "version_index = len([_ for _ in Path(result_dir_path).iterdir() if _.is_file()])\n",
    "version = f\"_v{version_index}\"\n",
    "\n",
    "result_name = \"processTime#waitTasks\" + version\n",
    "result_output_filename = f\"{filename_prefix}{result_name}{result_suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_excel(filename)\n",
    "    columns = df.columns.to_list()\n",
    "    data_dict = {col: df[col].to_list() for col in columns}\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def data_preprocess(filepath):\n",
    "    data = read_data(filepath)\n",
    "    # TODO more...\n",
    "\n",
    "    # to numpy\n",
    "    for key in data.keys():\n",
    "        data[key] = np.array(data[key])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_preprocess(file_path)\n",
    "\n",
    "# if wait time < 1 => no wait [ remove ]\n",
    "is_remove_no_wait = False\n",
    "\n",
    "if is_remove_no_wait:\n",
    "    index_list = list()\n",
    "    for key, value in dataset.items():\n",
    "        for v in value:\n",
    "            if key == 'worker_wait_time' and v < 1:\n",
    "                index_list.append(list(dataset.get(key)).index(v))\n",
    "\n",
    "    for key, value in dataset.items():\n",
    "        dataset[key] = [x for i, x in enumerate(value) if i not in index_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Style View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# # dataset is a dictionary\n",
    "\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "y = np.array(dataset.get('worker_wait_time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strandard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler       # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler         # type: ignore\n",
    "from sklearn.preprocessing import PowerTransformer     # type: ignore\n",
    "import numpy as np                                     # type: ignore\n",
    "\n",
    "_X = [dataset.get(\"request_num\"), dataset.get(\n",
    "    \"jobs_on_worker_node\")]\n",
    "\n",
    "for i in range(len(_X)):\n",
    "    _X[i] = np.array(_X[i]).reshape(-1, 1)\n",
    "    \n",
    "\n",
    "# _scaler = \"normalization\"\n",
    "_scaler = None\n",
    "\n",
    "if _scaler == \"standard\":\n",
    "    X_scaler = StandardScaler()\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "elif _scaler == \"normalization\":\n",
    "    X_scaler = MinMaxScaler()\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "elif _scaler == \"log\":\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = np.log1p(_X[i])\n",
    "elif _scaler == \"power\":\n",
    "    X_scaler = PowerTransformer(method='yeo-johnson')\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "for i in range(len(_X)):\n",
    "    _X[i] = _X[i].reshape(-1)\n",
    "\n",
    "X = np.array(\n",
    "    _X\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter combinations: 36\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the parameter ranges\n",
    "params = {\n",
    "    \"max_depth\": [3, 4, 5, 10],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [1000, 1500, 2000],\n",
    "    \"min_child_weight\": [1],\n",
    "    \"subsample\": [0.7],\n",
    "    \"colsample_bytree\": [0.8],\n",
    "    \"reg_alpha\": [1],\n",
    "    \"reg_lambda\": [1],\n",
    "}\n",
    "\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "parameter_combinations = [\n",
    "    dict(zip(params.keys(), combination))\n",
    "    for combination in itertools.product(*params.values())\n",
    "]\n",
    "\n",
    "# Print the number of parameter combinations and a few examples\n",
    "print(f\"Number of parameter combinations: {len(parameter_combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor # type: ignore\n",
    "import xgboost  # type: ignore\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # type: ignore\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# Create the XGBoost regressor model\n",
    "def create_model(params):\n",
    "    # if use gpu to add these two params\n",
    "    # - tree_method=\"hist\",\n",
    "    # - device=\"cuda\",\n",
    "    \n",
    "    return RandomForestRegressor(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        max_features=params[\"colsample_bytree\"],  # Equivalent to colsample_bytree in XGBoost\n",
    "        min_samples_split=params.get(\"min_samples_split\", 2),\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\", 1),\n",
    "        random_state=params.get(\"random_state\", 42),\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(\n",
    "    params, X_train, y_train, X_test: np.array, y_test: np.array\n",
    "):\n",
    "\n",
    "    model = create_model(params)\n",
    "\n",
    "    # Convert CuPy arrays to NumPy arrays\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = float(mean_squared_error(y_test, predictions))\n",
    "    mae = float(mean_absolute_error(y_test, predictions))\n",
    "    avg = float(np.mean(y_test))\n",
    "\n",
    "    # calculate diffirence and accuracy\n",
    "    data_list = list()\n",
    "    for i in range(len(y_test)):\n",
    "        acc = 0\n",
    "        diff = abs(y_test[i] - predictions[i])\n",
    "        if predictions[i] < 0:\n",
    "            acc = 0\n",
    "        else:\n",
    "            rate = diff / y_test[i]\n",
    "            if rate < 1 and rate >= 0:\n",
    "                acc = 1 - rate\n",
    "            if rate > 1:\n",
    "                acc = 0\n",
    "\n",
    "        data_list.append(\n",
    "            [\n",
    "                float(X_test[i][0]),\n",
    "                float(X_test[i][1]),\n",
    "                float(y_test[i]),\n",
    "                float(predictions[i]),\n",
    "                float(diff),\n",
    "                float(round(acc, 5)),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    results_tuple = {\"mse\": mse, \"mae\": mae, \"avg\": avg, \"model\": model, \"data_list\": data_list}\n",
    "    filtered_results = {k: v for k, v in results_tuple.items() if k != \"model\" and k != \"data_list\"}\n",
    "    print(filtered_results, f'\\n{params}', '\\n')\n",
    "    return results_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 1074.2300521483446, 'mae': 26.992937214635337, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 1077.1856853664615, 'mae': 27.037336500764418, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 1083.5827040857987, 'mae': 27.098230248609884, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 1074.2300521483446, 'mae': 26.992937214635337, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.05, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 1077.1856853664615, 'mae': 27.037336500764418, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.05, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 1083.5827040857987, 'mae': 27.098230248609884, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.05, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 1074.2300521483446, 'mae': 26.992937214635337, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 1077.1856853664615, 'mae': 27.037336500764418, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 1083.5827040857987, 'mae': 27.098230248609884, 'avg': 149.7200319290161} \n",
      "{'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 615.9746326025705, 'mae': 20.57670443738242, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 614.562390590597, 'mae': 20.614995251600007, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 610.6054954782484, 'mae': 20.546702534805203, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 615.9746326025705, 'mae': 20.57670443738242, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.05, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 614.562390590597, 'mae': 20.614995251600007, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.05, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 610.6054954782484, 'mae': 20.546702534805203, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.05, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 615.9746326025705, 'mae': 20.57670443738242, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.1, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 614.562390590597, 'mae': 20.614995251600007, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.1, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 610.6054954782484, 'mae': 20.546702534805203, 'avg': 149.7200319290161} \n",
      "{'max_depth': 4, 'learning_rate': 0.1, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 375.09030161362733, 'mae': 16.048932876435117, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 380.55001111665194, 'mae': 16.203645939194388, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 381.60456239300055, 'mae': 16.239797514448604, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 375.09030161362733, 'mae': 16.048932876435117, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 380.55001111665194, 'mae': 16.203645939194388, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 381.60456239300055, 'mae': 16.239797514448604, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 375.09030161362733, 'mae': 16.048932876435117, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 380.55001111665194, 'mae': 16.203645939194388, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 381.60456239300055, 'mae': 16.239797514448604, 'avg': 149.7200319290161} \n",
      "{'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 223.18642261820904, 'mae': 11.831026616646797, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 222.77345579509603, 'mae': 11.830339552744153, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 223.1520024239812, 'mae': 11.819794898306585, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.01, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 223.18642261820904, 'mae': 11.831026616646797, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.05, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 222.77345579509603, 'mae': 11.830339552744153, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.05, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 223.1520024239812, 'mae': 11.819794898306585, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.05, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 223.18642261820904, 'mae': 11.831026616646797, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.1, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 222.77345579509603, 'mae': 11.830339552744153, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.1, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "{'mse': 223.1520024239812, 'mae': 11.819794898306585, 'avg': 149.7200319290161} \n",
      "{'max_depth': 10, 'learning_rate': 0.1, 'n_estimators': 2000, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1} \n",
      "\n",
      "Best Parameters: {'max_depth': 10, 'learning_rate': 0.01, 'n_estimators': 1500, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Best MSE: 222.77345579509603\n",
      "Best MAE: 11.830339552744153\n",
      "Average: 149.7200319290161\n",
      "Results saved finished.\n",
      "[[370905.0, 185.0, 209.2069308757782, 218.00608991482892, 8.799159039050721, 0.95794], [308447.0, 41.0, 28.37110447883606, 37.17528671247814, 8.80418223364208, 0.68968], [183590.0, 193.0, 205.2394654750824, 218.9615984431832, 13.722132968100794, 0.93314], [236519.0, 77.0, 76.19845652580261, 75.81406596463457, 0.38439056116804693, 0.99496], [245356.0, 57.0, 47.94756126403809, 58.99701327320548, 11.04945200916739, 0.76955], [233951.0, 204.0, 218.4129946231842, 236.5601298197407, 18.14713519655649, 0.91691], [430853.0, 194.0, 227.217940568924, 229.50585826048052, 2.2879176915565154, 0.98993], [255777.0, 66.0, 67.49503326416016, 67.65168358476885, 0.15665032060869066, 0.99768], [142397.0, 38.0, 31.75894689559937, 38.83728063058055, 7.078333734981182, 0.77712], [393502.0, 241.0, 274.2089517116547, 273.9752928276613, 0.23365888399342793, 0.99915], [289541.0, 7.0, 12.1493501663208, 11.055927367885808, 1.0934227984349931, 0.91], [288353.0, 101.0, 107.5886745452881, 101.67556226258199, 5.913112282706109, 0.94504], [383707.0, 214.0, 229.8588376045227, 241.57702701495475, 11.718189410432046, 0.94902], [387907.0, 50.0, 46.80675768852234, 47.395521964597165, 0.5887642760748264, 0.98742], [245032.0, 191.0, 218.8765120506287, 219.81172032329343, 0.9352082726647382, 0.99573], [385186.0, 202.0, 211.0586938858032, 229.1300307196594, 18.071336833856208, 0.91438], [361435.0, 267.0, 301.3263144493103, 298.27301926392084, 3.0532951853894588, 0.98987], [351076.0, 19.0, 23.85439777374268, 25.214465982552653, 1.3600682088099738, 0.94298], [115560.0, 163.0, 177.3936719894409, 185.64776403125532, 8.254092041814431, 0.95347], [185878.0, 214.0, 234.5225930213928, 254.80496059708292, 20.28236757569013, 0.91352], [356875.0, 264.0, 298.7676420211792, 293.40720654572107, 5.360435475458132, 0.98206], [28985.0, 264.0, 319.4146063327789, 287.88762566386265, 31.526980668916224, 0.9013], [487937.0, 143.0, 152.9946467876434, 171.41121045676763, 18.41656366912423, 0.87963], [497543.0, 181.0, 190.0809178352356, 211.38865314089963, 21.30773530566404, 0.8879], [318537.0, 44.0, 40.9799485206604, 40.254689867527865, 0.7252586531325349, 0.9823], [155895.0, 246.0, 274.8764407634735, 282.86721224734424, 7.990771483870731, 0.97093], [165218.0, 269.0, 320.1739640235901, 310.5563664840676, 9.617597539522478, 0.96996], [204382.0, 110.0, 119.6567404270172, 117.17168863726873, 2.485051789748468, 0.97923], [287964.0, 55.0, 45.75074291229248, 59.61495557209797, 13.864212659805489, 0.69696], [342881.0, 172.0, 180.3351321220398, 194.13196059681417, 13.796828474774372, 0.92349], [6164.0, 255.0, 315.279643535614, 274.79941242128933, 40.48023111432468, 0.87161], [412001.0, 171.0, 217.7059087753296, 198.51269494401694, 19.193213831312647, 0.91184], [163150.0, 235.0, 268.0604846477509, 264.28806776327633, 3.7724168844745805, 0.98593], [341265.0, 88.0, 81.65401339530945, 86.77450837698181, 5.1204949816723655, 0.93729], [89869.0, 3.0, 0.007497072219848633, 10.23599247407502, 10.228495401855172, 0.0], [163431.0, 171.0, 217.5614898204803, 189.80704587149896, 27.754443948981333, 0.87243], [293286.0, 215.0, 254.8379073143005, 244.2919958479429, 10.545911466357609, 0.95862], [199379.0, 40.0, 27.66329336166382, 37.699634064824934, 10.036340703161116, 0.6372], [401587.0, 109.0, 99.80891919136047, 127.03457112990134, 27.225651938540864, 0.72722], [71696.0, 37.0, 29.92891407012939, 38.489125828390776, 8.560211758261385, 0.71398], [433965.0, 198.0, 241.6720194816589, 231.55529986257062, 10.116719619088286, 0.95814], [31589.0, 53.0, 44.84964609146118, 46.929754950164615, 2.080108858703433, 0.95362], [484451.0, 262.0, 307.588919878006, 295.6713617994397, 11.917558078566287, 0.96125], [453319.0, 94.0, 82.50860118865967, 102.80621899838016, 20.297617809720492, 0.75399], [210154.0, 21.0, 9.379688739776611, 25.92703600034218, 16.54734726056557, 0.0], [443625.0, 45.0, 38.57017207145691, 53.49146772653535, 14.921295655078438, 0.61314], [293293.0, 1.0, 0.009074687957763672, 11.593194130534206, 11.584119442576442, 0.0], [54914.0, 9.0, 6.676593542098999, 15.417854928316437, 8.741261386217438, 0.0], [147272.0, 220.0, 238.0752854347229, 254.4436005102888, 16.368315075565903, 0.93125], [58806.0, 15.0, 5.999073266983032, 17.109654961830028, 11.110581694846996, 0.0], [252010.0, 42.0, 37.53741025924683, 41.209589373168626, 3.6721791139217927, 0.90217], [258211.0, 92.0, 93.0580506324768, 96.84462790468038, 3.786577272203573, 0.95931], [188905.0, 69.0, 86.94960117340088, 69.20426006093713, 17.74534111246375, 0.79591], [107371.0, 216.0, 250.4785239696503, 248.24699065771566, 2.2315333119346406, 0.99109], [153964.0, 100.0, 92.45864224433899, 99.56472314743469, 7.106080903095702, 0.92314], [90288.0, 31.0, 32.73754596710205, 26.460275139981217, 6.277270827120834, 0.80825], [54654.0, 77.0, 51.77764821052551, 74.53127272285558, 22.753624512330063, 0.56055], [498461.0, 12.0, 12.42496156692505, 41.68754609334965, 29.262584526424604, 0.0], [141087.0, 105.0, 127.1286029815674, 113.27427551996091, 13.854327461606488, 0.89102], [147905.0, 45.0, 44.25922203063965, 44.41062097790896, 0.15139894726931402, 0.99658], [86976.0, 266.0, 320.9901256561279, 292.0292221953075, 28.96090346082036, 0.90978], [470561.0, 138.0, 160.0550398826599, 159.3602129346811, 0.694826947978811, 0.99566], [132659.0, 169.0, 177.6979601383209, 188.47448090349354, 10.776520765172648, 0.93935], [494065.0, 261.0, 289.1678237915039, 273.61642595344523, 15.551397838058676, 0.94622], [44349.0, 46.0, 29.77317547798157, 40.49309470837374, 10.719919230392168, 0.63995], [204752.0, 24.0, 14.59258317947388, 27.166672031325483, 12.574088851851602, 0.13832], [232364.0, 241.0, 279.5606548786163, 277.99543413511276, 1.5652207435035166, 0.9944], [421726.0, 26.0, 33.88074946403503, 25.824055222478975, 8.056694241556052, 0.7622], [380913.0, 125.0, 135.4879062175751, 135.5518991866725, 0.0639929690973986, 0.99953], [258455.0, 202.0, 242.3694312572479, 236.67012463712882, 5.699306620119074, 0.97649], [395641.0, 177.0, 228.0811095237732, 202.40370280310336, 25.677406720669836, 0.88742], [355324.0, 174.0, 227.0584681034088, 188.05326168352238, 39.005206419886434, 0.82822], [135441.0, 140.0, 171.3661842346191, 160.1978716568169, 11.168312577802226, 0.93483], [421399.0, 146.0, 185.9735045433044, 171.34778011719914, 14.62572442610525, 0.92136], [258422.0, 163.0, 171.3103861808777, 191.5987832199883, 20.288397039110578, 0.88157], [73085.0, 157.0, 174.6379146575928, 183.3759063204944, 8.737991662901607, 0.94997], [282270.0, 137.0, 161.182347536087, 157.4537492753931, 3.7285982606939, 0.97687], [419832.0, 39.0, 32.63949680328369, 43.849026130645846, 11.209529327362155, 0.65657], [12098.0, 243.0, 271.7858250141144, 263.33859618805513, 8.447228826059245, 0.96892], [422682.0, 250.0, 285.1274428367615, 274.9816819058959, 10.14576093086555, 0.96442], [23183.0, 78.0, 91.94563961029053, 77.99169962447509, 13.953939985815438, 0.84824], [244998.0, 49.0, 28.57234215736389, 45.22919862030009, 16.656856462936197, 0.41703], [33038.0, 256.0, 301.3835577964783, 285.0483627201766, 16.335195076301716, 0.9458], [177007.0, 87.0, 84.38933157920837, 86.38250264615374, 1.993171066945365, 0.97638], [459420.0, 167.0, 172.5193109512329, 191.7803899450322, 19.261078993799288, 0.88835], [372704.0, 52.0, 32.64063000679016, 38.00806163469119, 5.367431627901027, 0.83556], [476668.0, 93.0, 106.0722031593323, 94.55225328419927, 11.519949875133037, 0.8914], [214540.0, 219.0, 256.3508040904999, 250.84984122676596, 5.500962863733918, 0.97854], [323089.0, 161.0, 169.2796428203583, 187.59752393305175, 18.317881112693442, 0.89179], [20910.0, 141.0, 167.7634115219116, 167.9052667714207, 0.14185524950912054, 0.99915], [263876.0, 196.0, 206.5931534767151, 230.1758745675228, 23.582721090807723, 0.88585], [498492.0, 256.0, 295.5000464916229, 268.86779194947326, 26.632254542149667, 0.90987], [414667.0, 185.0, 196.7414879798889, 219.06812047348907, 22.326632493600187, 0.88652], [92303.0, 169.0, 211.1295773983002, 191.84883712693824, 19.280740271361964, 0.90868], [199144.0, 231.0, 263.0796005725861, 258.4604451119268, 4.619155460659329, 0.98244], [154803.0, 177.0, 229.086199760437, 192.22955710922426, 36.85664265121275, 0.83911], [34825.0, 51.0, 59.39009571075439, 48.13492785422407, 11.25516785653032, 0.81049], [49188.0, 43.0, 31.45810675621033, 39.35672897582495, 7.898622219614619, 0.74892], [492077.0, 235.0, 261.1288108825684, 258.6695916364987, 2.459219246069722, 0.99058], [61793.0, 10.0, 5.069785594940186, 15.97967471961678, 10.909889124676592, 0.0]]\n",
      "[[10, 0.01, 1500, 1, 0.7, 0.8, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to track the best parameters\n",
    "best_params = None\n",
    "best_result = None\n",
    "best_data = None\n",
    "\n",
    "# results param\n",
    "best_mse = float(\"inf\")\n",
    "best_mae = float(\"inf\")\n",
    "\n",
    "sheet_style = [\"num\", \"jobs\", \"X_test\", \"prediction\", \"difference\", \"accuracy\"]\n",
    "\n",
    "# control sheet style of excel written\n",
    "first_write = True\n",
    "\n",
    "# Evaluate each parameter combination\n",
    "for params in parameter_combinations:\n",
    "\n",
    "    # split dataset to train dataset and test dataset for every params group\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    results_tuple = evaluate_model(params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    filtered_results = {\n",
    "        k: v for k, v in results_tuple.items() if k != \"model\" and k != \"data_list\"\n",
    "    }\n",
    "\n",
    "    # update best model\n",
    "    if results_tuple['mse'] < best_mse:\n",
    "        best_mse = results_tuple[\"mse\"]\n",
    "        best_params = params\n",
    "        best_model = results_tuple[\"model\"]\n",
    "        best_result = filtered_results\n",
    "        best_data = results_tuple['data_list']\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best MSE:\", best_mse)\n",
    "print(\"Best MAE:\", best_result[\"mae\"])\n",
    "print(\"Average:\", best_result[\"avg\"])\n",
    "print(\"Results saved finished.\")\n",
    "\n",
    "params_keys_list = list(best_params.keys())\n",
    "params_values_list = list(best_params.values())\n",
    "\n",
    "to_excel(\n",
    "    data=best_data,\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=sheet_style,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,  # Create a new sheet for the best results\n",
    ")\n",
    "\n",
    "# best mse params\n",
    "to_excel(\n",
    "    data=[params_values_list],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=params_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best mse params\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb_tasks_time_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(Path\u001b[38;5;241m.\u001b[39mcwd() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelsfile\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m model_file)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m(model_path)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "model_file = \"xgb_tasks_time_v1\" + \".json\"\n",
    "model_path = str(Path.cwd() / \"modelsfile\" / model_file)\n",
    "best_model.save_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
