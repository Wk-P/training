{"cells":[{"cell_type":"markdown","metadata":{"id":"qgtH9_K1imY7"},"source":["### DATA PREPROGRESS"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":490,"status":"ok","timestamp":1715196153067,"user":{"displayName":"LINGXIAO ZHOU","userId":"00374870973427248310"},"user_tz":-540},"id":"wHuwHZf_jw9N"},"outputs":[],"source":["import re\n","import numpy as np\n","import json\n","\n","def data_preprocess(filepath):\n","    # data_all = np.genfromtxt(filepath, delimiter=' ')\n","    # data = data_all[:8000]\n","\n","    data = np.genfromtxt(filepath, delimiter=' ', dtype=float)\n","\n","    for d in data:\n","        # d[0] = float(d[0] * 1000)\n","        # d[2] = float(d[2] * 1000)\n","        # d[3] = float(d[2] * 1000)\n","        # d[4] = float(d[2] * 1000)\n","        pass\n","\n","    training_x = data[:, 1:]\n","\n","    training_y = data[:, :1]\n","\n","    return training_x, training_y\n","\n","# Data preprocessing\n","file_path = \"../training_data/trainingDataSet_CPU_v1_10.txt\"\n","training_x, training_y = data_preprocess(file_path)"]},{"cell_type":"markdown","metadata":{"id":"ct0ytUeniiq0"},"source":["### MODEL COMPILE & FIT"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1715196153561,"user":{"displayName":"LINGXIAO ZHOU","userId":"00374870973427248310"},"user_tz":-540},"id":"q0bCz2Ma4sQu"},"outputs":[],"source":["### Data preprocessing using MinMaxScaler\n","# create MinMaxScaler Object\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","x_scaler = MinMaxScaler()\n","y_scaler = MinMaxScaler()\n","\n","\n","# scaled_training_x = training_x[:, 0].reshape(-1, 1)\n","# scaled_training_y = training_y[:].reshape(-1, 1)\n","\n","# training_x[:, 0] = scaled_training_x[:, 0]\n","# training_y = scaled_training_y\n","\n","# Define the split points based on time\n","train_size = int(len(training_x) * 0.8)\n","val_size = int(len(training_x) * 0.1)\n","\n","# Split the data\n","x_train = training_x[:train_size]\n","y_train = training_y[:train_size]\n","\n","x_val = training_x[train_size + val_size:]\n","y_val = training_y[train_size + val_size:]\n","\n","\n","# test data from other file\n","x_test = training_x[:train_size + val_size]\n","y_test = training_y[:train_size + val_size]\n","\n","# x_train_first_column = x_train[:, 0].reshape(-1, 1)\n","# scaled_x_train_first_column = x_scaler.fit_transform(x_train_first_column)\n","# x_train[:, 0] = scaled_x_train_first_column.flatten()\n","# y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1))  # reshap to 2D\n","\n","# make the same sacling on valid data set and test data set\n","# x_val_scaled = x_scaler.transform(x_val)\n","# x_val_first_column = x_val[:, 0].reshape(-1, 1)\n","# scaled_x_val_first_column = x_scaler.fit_transform(x_val_first_column)\n","# x_val[:, 0] = scaled_x_val_first_column.flatten()\n","# y_val_scaled = y_scaler.transform(y_val.reshape(-1, 1))  # reshap to 2D\n","\n","\n","# x_test_first_column = x_test[:, 0].reshape(-1, 1)\n","# scaled_x_test_first_column = x_scaler.fit_transform(x_test_first_column)\n","# x_test[:, 0] = scaled_x_test_first_column.flatten()\n","# y_test_scaled = y_scaler.transform(y_test.reshape(-1, 1))  # reshap to 2D"]},{"cell_type":"markdown","metadata":{"id":"B1eEvGJzL186"},"source":["### NORMALIZATION"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":342,"status":"ok","timestamp":1715196153902,"user":{"displayName":"LINGXIAO ZHOU","userId":"00374870973427248310"},"user_tz":-540},"id":"VGTTcyJALYSX"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout, Input\n","from keras.callbacks import Callback, EarlyStopping\n","from keras.optimizers import Adam\n","\n","\n","def create_sequences(dataset_x, dataset_y, time_steps):\n","    dataX, dataY = [], []\n","\n","    # scale for data set\n","    if dataset_x.shape[0] < time_steps:\n","        # Handle the case where the input data is smaller than time_steps\n","        # You can choose to pad the sequence or handle it in a way that makes sense for your data\n","        # For example, you can replicate the single time step to create a sequence\n","        x_sequence = np.tile(dataset_x, (time_steps, 1))\n","        y_sequence = np.tile(dataset_y, (time_steps, 1))\n","        dataX.append(x_sequence)\n","        dataY.append(y_sequence)\n","    else:\n","        for i in range(dataset_x.shape[0] - time_steps + 1):\n","            x_sequence = dataset_x[i:i + time_steps, :]\n","            y_sequence = dataset_y[i + time_steps - 1]\n","            dataX.append(x_sequence)\n","            dataY.append(y_sequence)\n","\n","    return np.array(dataX), np.array(dataY)\n","\n","# Create sequences for each set\n","time_steps = 50\n","\n","\n","# x_test = training_x[train_size:]\n","# y_test = one_hot_encoding[train_size:]\n","\n","# Create sequences for each set\n","x_train_sequences, y_train_sequences = create_sequences(x_train, y_train, time_steps)\n","x_val_sequences, y_val_sequences = create_sequences(x_val, y_val, time_steps)\n","x_test_sequences, y_test_sequences = create_sequences(x_test, y_test, time_steps)\n","\n","\n","# Initialize LossHistory with validation data\n","class LossHistory(Callback):\n","    def __init__(self, x_train, y_train, x_val, y_val):\n","        super().__init__()\n","        self.train_data = (x_train, y_train)\n","        self.validation_data = (x_val, y_val)\n","        self.losses = []\n","        self.val_losses = []\n","        self.train_errors = []\n","        self.val_errors = []\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.losses.append(logs['loss'])\n","        self.val_losses.append(logs.get('val_loss'))\n","        self.train_errors.append(logs.get('mean_absolute_error'))\n","        self.val_errors.append(logs.get('val_mean_absolute_error'))"]},{"cell_type":"markdown","metadata":{"id":"k_HW6eWMLZMX"},"source":["### FITTING"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"executionInfo":{"elapsed":58616,"status":"error","timestamp":1715196212517,"user":{"displayName":"LINGXIAO ZHOU","userId":"00374870973427248310"},"user_tz":-540},"id":"F3ZXcO-_j4eM","outputId":"f89bb4c1-94d0-4916-da3d-f77068c91b52"},"outputs":[{"name":"stdout","output_type":"stream","text":["epochs: 200\n","batch: 64\n","units: 50\n","hidden layers: 0\n","Epoch 1/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 11019940.0000 - mean_absolute_error: 1150.9277 - val_loss: 2427.7529 - val_mean_absolute_error: 38.1722\n","Epoch 2/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 1607.9882 - mean_absolute_error: 28.5669 - val_loss: 473.4884 - val_mean_absolute_error: 16.3104\n","Epoch 3/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 360.1196 - mean_absolute_error: 13.9029 - val_loss: 199.7854 - val_mean_absolute_error: 10.8358\n","Epoch 4/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 193.2230 - mean_absolute_error: 10.6196 - val_loss: 186.5913 - val_mean_absolute_error: 10.8078\n","Epoch 5/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 138.9224 - mean_absolute_error: 9.0738 - val_loss: 150.9029 - val_mean_absolute_error: 9.5236\n","Epoch 6/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 109.3489 - mean_absolute_error: 8.0263 - val_loss: 85.9903 - val_mean_absolute_error: 7.0360\n","Epoch 7/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 83.0316 - mean_absolute_error: 6.9754 - val_loss: 106.0420 - val_mean_absolute_error: 8.2223\n","Epoch 8/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 90.5184 - mean_absolute_error: 7.3914 - val_loss: 201.1441 - val_mean_absolute_error: 13.1058\n","Epoch 9/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 133.6221 - mean_absolute_error: 8.7813 - val_loss: 41.8534 - val_mean_absolute_error: 4.6423\n","Epoch 10/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 304.6836 - mean_absolute_error: 13.6826 - val_loss: 27.1788 - val_mean_absolute_error: 4.0496\n","Epoch 11/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 140.5280 - mean_absolute_error: 9.1708 - val_loss: 7561.0898 - val_mean_absolute_error: 86.3036\n","Epoch 12/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 699.5262 - mean_absolute_error: 12.2304 - val_loss: 25.0677 - val_mean_absolute_error: 3.4728\n","Epoch 13/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 29.3424 - mean_absolute_error: 3.9606 - val_loss: 32.0690 - val_mean_absolute_error: 4.5393\n","Epoch 14/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 43.3806 - mean_absolute_error: 4.6399 - val_loss: 138.3270 - val_mean_absolute_error: 10.5467\n","Epoch 15/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 1061.7705 - mean_absolute_error: 8.6759 - val_loss: 345.0428 - val_mean_absolute_error: 8.1970\n","Epoch 16/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 389.4340 - mean_absolute_error: 9.1297 - val_loss: 53.8855 - val_mean_absolute_error: 5.5676\n","Epoch 17/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 43.2965 - mean_absolute_error: 4.9035 - val_loss: 24.3359 - val_mean_absolute_error: 3.4524\n","Epoch 18/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 80.9559 - mean_absolute_error: 6.7930 - val_loss: 28.7344 - val_mean_absolute_error: 3.4681\n","Epoch 19/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 125.7062 - mean_absolute_error: 8.2410 - val_loss: 58.9722 - val_mean_absolute_error: 6.4611\n","Epoch 20/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 88.6164 - mean_absolute_error: 6.9622 - val_loss: 158.8929 - val_mean_absolute_error: 10.6910\n","Epoch 21/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 110.0299 - mean_absolute_error: 8.0580 - val_loss: 62.3821 - val_mean_absolute_error: 6.8523\n","Epoch 22/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 65.8801 - mean_absolute_error: 6.0538 - val_loss: 42.4658 - val_mean_absolute_error: 4.5592\n","Epoch 23/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 86.5641 - mean_absolute_error: 6.8163 - val_loss: 48.6229 - val_mean_absolute_error: 5.5930\n","Epoch 24/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 77.5791 - mean_absolute_error: 6.4826 - val_loss: 24.6513 - val_mean_absolute_error: 3.8090\n","Epoch 25/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 64.9161 - mean_absolute_error: 5.9414 - val_loss: 649.8718 - val_mean_absolute_error: 23.8567\n","Epoch 26/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 114.9669 - mean_absolute_error: 7.6645 - val_loss: 24.5128 - val_mean_absolute_error: 3.7833\n","Epoch 27/200\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 80.3164 - mean_absolute_error: 6.3244 - val_loss: 89.1870 - val_mean_absolute_error: 7.6451\n","\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n","MAE: 3.482576142061643\n","pred: [-0.5539037] | real: [12.07354832]\n","pred: [7.5248933] | real: [10.56662965]\n","pred: [3.0544598] | real: [15.8947897]\n","pred: [5.8902397] | real: [16.50529051]\n","pred: [5.3995905] | real: [16.00296664]\n","pred: [7.816468] | real: [20.03378606]\n","pred: [9.600798] | real: [13.99754524]\n","pred: [3.2888072] | real: [12.6154778]\n","pred: [1.7650855] | real: [5.98408818]\n","pred: [7.2798023] | real: [16.37700558]\n","pred: [3.9393666] | real: [7.95711684]\n","pred: [6.0549765] | real: [8.29400682]\n","pred: [-0.43399507] | real: [4.65881395]\n","pred: [2.6302419] | real: [8.22546697]\n","pred: [7.46018] | real: [3.43993115]\n","pred: [2.481459] | real: [0.22870922]\n","pred: [1.693454] | real: [0.38993955]\n","pred: [1.8464489] | real: [0.66369367]\n","pred: [0.5554436] | real: [0.44879103]\n","pred: [4.610896] | real: [1.94954133]\n","pred: [7.3426027] | real: [3.52844286]\n","pred: [3.9964511] | real: [2.74496722]\n","pred: [6.1976624] | real: [1.04674244]\n","pred: [-0.6165808] | real: [0.91578531]\n","pred: [9.051982] | real: [4.58082652]\n","pred: [3.3319807] | real: [2.48695683]\n","pred: [5.82485] | real: [2.96786165]\n","pred: [4.3678784] | real: [2.65296745]\n","pred: [-1.0546453] | real: [1.00142026]\n","pred: [9.373286] | real: [3.11701059]\n","pred: [6.96047] | real: [2.60095286]\n","pred: [10.102026] | real: [8.12490821]\n","pred: [3.7573388] | real: [0.88722205]\n","pred: [3.415283] | real: [2.55114961]\n","pred: [6.224509] | real: [2.63708067]\n","pred: [4.026072] | real: [1.05382466]\n","pred: [6.4964476] | real: [4.17333102]\n","pred: [9.830256] | real: [3.41364813]\n","pred: [0.28560108] | real: [3.37400842]\n","pred: [7.1961713] | real: [12.1985414]\n"]}],"source":["from keras.callbacks import TensorBoard\n","import os\n","import datetime\n","\n","# log\n","log_dir = os.path.join(\"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","\n","def add_hidden_layer(model, units, activation, layers):\n","\n","    if layers > 1:\n","\n","        for layer in range(layers - 1):\n","\n","            model.add(LSTM(units=units, activation=activation, return_sequences=True))\n","\n","    model.add(LSTM(units=units, activation=activation, return_sequences=False))\n","\n","\n","# loop params\n","\n","LSTM_units = 50\n","\n","Stop_patience = 10\n","\n","Batch_size = 64\n","\n","Learning_rate = 1e-2\n","\n","Epochs = 200\n","\n","Layers = 0\n","\n","Activation = \"softmax\"\n","\n","\n","# loss_function = 'mean_absolute_error'  # Assuming you are doing regression\n","\n","# loss_function = 'categorical_crossentropy'\n","\n","# loss_function = 'sparse_categorical_crossentropy'\n","\n","loss_function = 'mean_squared_error'\n","\n","\n","# Initialize LossHistory with validation data\n","\n","history = LossHistory(x_train_sequences, y_train_sequences, x_val_sequences, y_val_sequences)\n","\n","\n","def model_fit():\n","\n","\n","    print(\"epochs:\", Epochs)\n","\n","    print(\"batch:\", Batch_size)\n","\n","    print(\"units:\", LSTM_units)\n","\n","\n","    # Build LSTM model\n","\n","    model = Sequential()\n","\n","    # Adding LSTM layer with L2 regularization\n","    model.add(Input(shape=(x_train_sequences.shape[1], x_train_sequences.shape[2])))\n","\n","    model.add(LSTM(units=LSTM_units, activation=Activation, return_sequences=False))  # Regularization on the weights\n","\n","\n","    # add_hidden_layer(model, LSTM_units, 'sigmoid', Layers)\n","\n","    print(\"hidden layers:\", Layers)\n","\n","\n","    # full con layer\n","\n","    # model.add(Dense(units=32))\n","\n","    model.add(Dense(units=1))\n","\n","\n","    # Compile model\n","\n","    model.compile(optimizer=Adam(learning_rate=Learning_rate), loss=loss_function, metrics=['mean_absolute_error'])\n","\n","\n","    # Define early stopping\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=Stop_patience, restore_best_weights=True)\n","\n","    # early_stopping = EarlyStopping(monitor='val_mean_absolute_error', patience=Stop_patience, restore_best_weights=True)\n","\n","\n","    # Train the model with early stopping\n","\n","    model.fit(x_train_sequences, y_train_sequences, epochs=Epochs, batch_size=Batch_size,\n","\n","            validation_data=(x_val_sequences, y_val_sequences), callbacks=[history, early_stopping, tensorboard_callback])\n","\n","\n","    prediction_results = model.predict(x_test_sequences)\n","\n","\n","    _abs = np.abs(y_test_sequences - prediction_results)\n","\n","    mae = np.mean(_abs)\n","\n","\n","    print(\"MAE:\", mae)\n","\n","\n","    for i in range(40):\n","\n","        print(f\"pred: {prediction_results[i]} | real: {y_test_sequences[i]}\")\n","\n","\n","model_fit()\n","\n","\n","# MSE\n","\n","# mse = mean_squared_error(y_test, prediction_results)\n","\n","# print(\"Mean Squared Error:\", mse)\n","\n","\n","# RMSE\n","\n","# rmse = np.sqrt(mse)\n","\n","# print(\"Mean Squared Error:\", mse)\n","\n","\n","# MAE\n","\n","# mae = mean_absolute_error(y_test_sequences, prediction_results)\n","\n","# print(\"Mean Absoluted Error:\", mae)\n","\n","\n","# from sklearn.metrics import mean_squared_error\n","\n","\n","# mse = mean_squared_error(y_test_sequences, prediction_results)\n","\n","# print(\"Mean Squared Error:\", mse)"]},{"cell_type":"markdown","metadata":{"id":"a53Vs3uAibih"},"source":["### SAVE MODEL"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1715196212518,"user":{"displayName":"LINGXIAO ZHOU","userId":"00374870973427248310"},"user_tz":-540},"id":"O1YJC_q-G-JF"},"outputs":[],"source":["# Save the model\n","    # model.save(\"/content/drive/MyDrive/LSTM/predict_model_2_0v.keras\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNCkyDBPwpKDBZmdmhechB3","gpuType":"T4","mount_file_id":"1NLGgGq5VOK54JvoBCH_NFc1AcJU7dBFP","provenance":[{"file_id":"1IoRKvFLnhdaROtNT4BDeOHAptBELr5wc","timestamp":1713973444923},{"file_id":"1oKKWNRjGFCyRAq7WE_FI6_Dw1ovcQjRn","timestamp":1708701671512}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
