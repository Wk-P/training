{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openpyxl import Workbook, load_workbook  # type: ignore\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def to_excel(\n",
    "    data, filename, sheet_style, result_dir_path, new_sheet=False, sheet_name=\"Sheet1\"\n",
    "):\n",
    "\n",
    "    if not os.path.exists(result_dir_path):\n",
    "        os.makedirs(result_dir_path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(result_dir_path, f\"{filename}.xlsx\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        workbook = load_workbook(file_path)\n",
    "        if new_sheet:\n",
    "            sheet = workbook.create_sheet(title=sheet_name)\n",
    "\n",
    "        else:\n",
    "            sheet = workbook.active\n",
    "    else:\n",
    "        workbook = Workbook()\n",
    "        default_sheet = workbook.active\n",
    "        workbook.remove(default_sheet)\n",
    "        sheet = workbook.create_sheet(title=sheet_name)\n",
    "        \n",
    "    if sheet_style:\n",
    "        sheet.append(sheet_style)\n",
    "\n",
    "\n",
    "    if new_sheet:\n",
    "        print(data)\n",
    "    # write data into file\n",
    "    for row in data:\n",
    "        sheet.append(row)\n",
    "\n",
    "    workbook.save(filename=f\"{result_dir_path}\\\\{filename}.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# read input dataset\n",
    "filename_prefix = (\n",
    "    \"RandomRequestNumberclientv_single_worker_node#loops5#requests_batch15#Thu-Aug-22-19-06-23-2024\"\n",
    ")\n",
    "\n",
    "\n",
    "dataset_read_filename = filename_prefix\n",
    "training_data_dir = Path.cwd().parent / \"training_data\" / \"data_set7\"\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "file_path = f\"{training_data_dir}\\\\{dataset_read_filename}.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "# set result output filename and path\n",
    "result_suffix = \"result\"\n",
    "\n",
    "result_dir_path = Path.cwd().parent / \"results\" / \"result_processTime_waitTasks_v3\"\n",
    "\n",
    "if not os.path.exists(result_dir_path):\n",
    "    os.makedirs(result_dir_path)\n",
    "\n",
    "version_index = len([_ for _ in Path(result_dir_path).iterdir() if _.is_file()])\n",
    "version = f\"_v{version_index}\"\n",
    "\n",
    "result_name = \"processTime#waitTasks\" + version\n",
    "result_output_filename = f\"{filename_prefix}{result_name}{result_suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_excel(filename)\n",
    "    columns = df.columns.to_list()\n",
    "    data_dict = {col: df[col].to_list() for col in columns}\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def data_preprocess(filepath):\n",
    "    data = read_data(filepath)\n",
    "    # TODO more...\n",
    "\n",
    "    # to numpy\n",
    "    for key in data.keys():\n",
    "        data[key] = np.array(data[key])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_preprocess(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Style View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# # dataset is a dictionary\n",
    "\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "import cupy as cp\n",
    "\n",
    "y = cp.array(dataset.get(\"processed_and_waited_time_on_manager_node\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strandard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler       # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "x0 = np.array(dataset.get(\"request_num\")).reshape(-1, 1)\n",
    "x1 = np.array(dataset.get(\"sub_processing_tasks_on_manager_node\")).reshape(-1, 1)\n",
    "\n",
    "\n",
    "_scaler = \"\"\n",
    "\n",
    "if _scaler == \"standard\":\n",
    "    X_scaler = StandardScaler()\n",
    "    x0 = X_scaler.fit_transform(x0)\n",
    "    x1 = X_scaler.fit_transform(x1)\n",
    "elif _scaler == \"normalization\":\n",
    "    X_scaler = MinMaxScaler()\n",
    "    x0 = X_scaler.fit_transform(x0)\n",
    "    x1 = X_scaler.fit_transform(x1)\n",
    "elif _scaler == \"log\":\n",
    "    x0 = np.log1p(x0)\n",
    "    x1 = np.log1p(x1)\n",
    "elif _scaler == \"power\":\n",
    "    X_scaler = PowerTransformer(method='yeo-johnson')\n",
    "    x0 = X_scaler.fit_transform(x0)\n",
    "    x1 = X_scaler.fit_transform(x1)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "x0 = x0.reshape(-1)\n",
    "x1 = x1.reshape(-1)\n",
    "\n",
    "X = cp.asarray(np.array(\n",
    "    [x0, x1]\n",
    ").T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter combinations: 2400\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the parameter ranges\n",
    "params = {\n",
    "    \"max_depth\": [3],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"n_estimators\": [i for i in range(1000, 4000, 100)],\n",
    "    \"min_child_weight\": [1],\n",
    "    \"subsample\": [0.1],\n",
    "    \"colsample_bytree\": [0.1],\n",
    "    \"reg_alpha\": [0, 0.1],\n",
    "    \"reg_lambda\": [i / 10 for i in range(10, 50, 1)],\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     \"max_depth\": [3],\n",
    "#     \"learning_rate\": [0.01],\n",
    "#     \"n_estimators\": [3800],\n",
    "#     \"min_child_weight\": [1],\n",
    "#     \"subsample\": [0.1],\n",
    "#     \"colsample_bytree\": [0.1],\n",
    "#     \"reg_alpha\": [0],\n",
    "#     \"reg_lambda\": [3.6],\n",
    "# }\n",
    "\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "parameter_combinations = [\n",
    "    dict(zip(params.keys(), combination))\n",
    "    for combination in itertools.product(*params.values())\n",
    "]\n",
    "\n",
    "# Print the number of parameter combinations and a few examples\n",
    "print(f\"Number of parameter combinations: {len(parameter_combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor  # type: ignore\n",
    "import xgboost  # type: ignore\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # type: ignore\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# Create the XGBoost regressor model\n",
    "def create_model(params):\n",
    "    # if use gpu to add these two params\n",
    "    # - tree_method=\"hist\",\n",
    "    # - device=\"cuda\",\n",
    "    \n",
    "    return XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        subsample=params[\"subsample\"],\n",
    "        colsample_bytree=params[\"colsample_bytree\"],\n",
    "        reg_alpha=params[\"reg_alpha\"],\n",
    "        reg_lambda=params[\"reg_lambda\"],\n",
    "        device=\"cuda\",\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(\n",
    "    params, X_train, y_train, X_test: np.array, y_test: np.array\n",
    ") -> Tuple[np.float64, xgboost.Booster]:\n",
    "\n",
    "    model = create_model(params)\n",
    "\n",
    "    # Convert CuPy arrays to NumPy arrays\n",
    "\n",
    "    model.fit(X_train, y_train, verbose=True)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # typecasting  cp -> np\n",
    "    y_test_np = cp.asnumpy(y_test)\n",
    "    X_test_np = cp.asnumpy(X_test)\n",
    "    predictions_np = cp.asnumpy(predictions)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test_np, predictions_np)\n",
    "    rmse = mean_squared_error(y_test_np, predictions_np)\n",
    "    mae = mean_absolute_error(y_test_np, predictions_np)\n",
    "    avg = np.mean(y_test_np)\n",
    "    avg_acc = 100 * (avg - mae) / avg\n",
    "\n",
    "    # calculate diffirence and accuracy\n",
    "    data_list = list()\n",
    "    for i in range(len(y_test_np)):\n",
    "        acc = 0\n",
    "        diff = abs(y_test_np[i] - predictions_np[i])\n",
    "        if predictions[i] < 0:\n",
    "            acc = 0\n",
    "        else:\n",
    "            rate = diff / y_test_np[i]\n",
    "            if rate < 1 and rate >= 0:\n",
    "                acc = 1 - rate\n",
    "            if rate > 1:\n",
    "                acc = 0\n",
    "        data_list.append(\n",
    "            [\n",
    "                X_test_np[i][0],\n",
    "                X_test_np[i][1],\n",
    "                y_test_np[i],\n",
    "                predictions_np[i],\n",
    "                diff,\n",
    "                round(acc, 5),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    results_tuple = {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"avg\": avg, \"avg_acc\": avg_acc, \"model\": model, \"data_list\": data_list}\n",
    "    filtered_results = {k: v for k, v in results_tuple.items() if k != \"model\" and k != \"data_list\"}\n",
    "    print(filtered_results, f'\\n{params}', '\\n')\n",
    "    return results_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:15:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cpu, while the input data is on: cuda:0.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': np.float64(5.443897973317494), 'rmse': np.float64(5.443897973317494), 'mae': np.float64(1.7933801571528118), 'avg': np.float64(6.052612654368082), 'avg_acc': np.float64(70.37014823906573)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.0} \n",
      "\n",
      "{'mse': np.float64(7.732841119971334), 'rmse': np.float64(7.732841119971334), 'mae': np.float64(2.1333469271659853), 'avg': np.float64(5.443565893173218), 'avg_acc': np.float64(60.80975285260314)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.1} \n",
      "\n",
      "{'mse': np.float64(7.214438514567858), 'rmse': np.float64(7.214438514567858), 'mae': np.float64(2.2767220099767047), 'avg': np.float64(4.002719338734945), 'avg_acc': np.float64(43.12061832703314)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.2} \n",
      "\n",
      "{'mse': np.float64(11.784337055147773), 'rmse': np.float64(11.784337055147773), 'mae': np.float64(2.6714122017224633), 'avg': np.float64(5.421615505218506), 'avg_acc': np.float64(50.726638597828824)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.3} \n",
      "\n",
      "{'mse': np.float64(4.5587506529456165), 'rmse': np.float64(4.5587506529456165), 'mae': np.float64(1.4576613346735638), 'avg': np.float64(5.213558085759481), 'avg_acc': np.float64(72.04094956465379)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.4} \n",
      "\n",
      "{'mse': np.float64(20.593130313004817), 'rmse': np.float64(20.593130313004817), 'mae': np.float64(3.1694712162017824), 'avg': np.float64(6.3112386703491214), 'avg_acc': np.float64(49.78052040572797)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.5} \n",
      "\n",
      "{'mse': np.float64(7.367431525639188), 'rmse': np.float64(7.367431525639188), 'mae': np.float64(2.2428267478942874), 'avg': np.float64(4.708989667892456), 'avg_acc': np.float64(52.37138099523413)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.6} \n",
      "\n",
      "{'mse': np.float64(7.3053257409909635), 'rmse': np.float64(7.3053257409909635), 'mae': np.float64(1.951858456929525), 'avg': np.float64(6.705480178197225), 'avg_acc': np.float64(70.89159306926348)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.7} \n",
      "\n",
      "{'mse': np.float64(4.33032216237803), 'rmse': np.float64(4.33032216237803), 'mae': np.float64(1.828922398885091), 'avg': np.float64(4.55231154759725), 'avg_acc': np.float64(59.82431387301663)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.8} \n",
      "\n",
      "{'mse': np.float64(15.508797333314245), 'rmse': np.float64(15.508797333314245), 'mae': np.float64(2.3376295804977416), 'avg': np.float64(5.604366699854533), 'avg_acc': np.float64(58.289139421258476)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.9} \n",
      "\n",
      "{'mse': np.float64(5.7461130847462405), 'rmse': np.float64(5.7461130847462405), 'mae': np.float64(1.7961338043212893), 'avg': np.float64(6.115278244018555), 'avg_acc': np.float64(70.62874766036828)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.0} \n",
      "\n",
      "{'mse': np.float64(6.471675249202721), 'rmse': np.float64(6.471675249202721), 'mae': np.float64(1.8143678029378256), 'avg': np.float64(5.256509669621786), 'avg_acc': np.float64(65.48341167479728)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.1} \n",
      "\n",
      "{'mse': np.float64(7.444498580814909), 'rmse': np.float64(7.444498580814909), 'mae': np.float64(2.226242510477702), 'avg': np.float64(5.816329002380371), 'avg_acc': np.float64(61.72426784030619)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.2} \n",
      "\n",
      "{'mse': np.float64(4.03267415329155), 'rmse': np.float64(4.03267415329155), 'mae': np.float64(1.8083234310150147), 'avg': np.float64(4.106456327438354), 'avg_acc': np.float64(55.963894734926754)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.3} \n",
      "\n",
      "{'mse': np.float64(4.442236942804327), 'rmse': np.float64(4.442236942804327), 'mae': np.float64(1.6197691599527995), 'avg': np.float64(4.934637324015299), 'avg_acc': np.float64(67.17551759944136)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.4} \n",
      "\n",
      "{'mse': np.float64(15.735962571469258), 'rmse': np.float64(15.735962571469258), 'mae': np.float64(2.495695225397746), 'avg': np.float64(5.6644227504730225), 'avg_acc': np.float64(55.9408727890351)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.5} \n",
      "\n",
      "{'mse': np.float64(14.099081681427123), 'rmse': np.float64(14.099081681427123), 'mae': np.float64(2.119051392873128), 'avg': np.float64(5.579001108805339), 'avg_acc': np.float64(62.01736921097526)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.6} \n",
      "\n",
      "{'mse': np.float64(7.17459020420174), 'rmse': np.float64(7.17459020420174), 'mae': np.float64(2.1344993472099305), 'avg': np.float64(5.27283714612325), 'avg_acc': np.float64(59.51895937504386)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.7} \n",
      "\n",
      "{'mse': np.float64(16.676109301435492), 'rmse': np.float64(16.676109301435492), 'mae': np.float64(2.391126362482707), 'avg': np.float64(5.95023315747579), 'avg_acc': np.float64(59.81457702243938)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.8} \n",
      "\n",
      "{'mse': np.float64(14.940361392539442), 'rmse': np.float64(14.940361392539442), 'mae': np.float64(2.3299986362457275), 'avg': np.float64(5.013130935033162), 'avg_acc': np.float64(53.52208696638971)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.9} \n",
      "\n",
      "{'mse': np.float64(6.914853466389347), 'rmse': np.float64(6.914853466389347), 'mae': np.float64(2.0772036949793495), 'avg': np.float64(4.458071613311768), 'avg_acc': np.float64(53.40578000638583)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.0} \n",
      "\n",
      "{'mse': np.float64(7.509497329048077), 'rmse': np.float64(7.509497329048077), 'mae': np.float64(2.162334267298381), 'avg': np.float64(6.222364409764608), 'avg_acc': np.float64(65.24899339059793)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.1} \n",
      "\n",
      "{'mse': np.float64(5.4419000285538015), 'rmse': np.float64(5.4419000285538015), 'mae': np.float64(1.9480730692545574), 'avg': np.float64(4.303013261159261), 'avg_acc': np.float64(54.72770007848562)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.2} \n",
      "\n",
      "{'mse': np.float64(4.214943212395099), 'rmse': np.float64(4.214943212395099), 'mae': np.float64(1.8046154181162517), 'avg': np.float64(3.7047039031982423), 'avg_acc': np.float64(51.288538429256356)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.3} \n",
      "\n",
      "{'mse': np.float64(7.728766183179846), 'rmse': np.float64(7.728766183179846), 'mae': np.float64(2.4340229988098145), 'avg': np.float64(5.000846211115519), 'avg_acc': np.float64(51.32777741895673)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.4} \n",
      "\n",
      "{'mse': np.float64(7.279573696140045), 'rmse': np.float64(7.279573696140045), 'mae': np.float64(2.377137978871664), 'avg': np.float64(4.732505400975545), 'avg_acc': np.float64(49.76998909749479)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.5} \n",
      "\n",
      "{'mse': np.float64(15.670311816839876), 'rmse': np.float64(15.670311816839876), 'mae': np.float64(2.50405109723409), 'avg': np.float64(6.214703989028931), 'avg_acc': np.float64(59.70763689381516)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.6} \n",
      "\n",
      "{'mse': np.float64(8.648380168492652), 'rmse': np.float64(8.648380168492652), 'mae': np.float64(2.3995148658752443), 'avg': np.float64(6.3636997699737545), 'avg_acc': np.float64(62.29371352185679)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.7} \n",
      "\n",
      "{'mse': np.float64(2.601683398235025), 'rmse': np.float64(2.601683398235025), 'mae': np.float64(1.3959063371022542), 'avg': np.float64(5.806274954477946), 'avg_acc': np.float64(75.95865941509201)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.8} \n",
      "\n",
      "{'mse': np.float64(5.369125733445042), 'rmse': np.float64(5.369125733445042), 'mae': np.float64(1.8099438508351648), 'avg': np.float64(5.524706745147705), 'avg_acc': np.float64(67.23909640226931)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 3.9} \n",
      "\n",
      "{'mse': np.float64(5.141824848540449), 'rmse': np.float64(5.141824848540449), 'mae': np.float64(1.5693365255991616), 'avg': np.float64(5.37304884592692), 'avg_acc': np.float64(70.79243888153356)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 4.0} \n",
      "\n",
      "{'mse': np.float64(3.6665742267074823), 'rmse': np.float64(3.6665742267074823), 'mae': np.float64(1.601707951227824), 'avg': np.float64(4.868346929550171), 'avg_acc': np.float64(67.09955197511324)} \n",
      "{'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 1000, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 4.1} \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m         first_write \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_output_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43msheet_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult_dir_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dir_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnew_sheet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest MSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_mse)\n",
      "Cell \u001b[1;32mIn[19], line 39\u001b[0m, in \u001b[0;36mto_excel\u001b[1;34m(data, filename, sheet_style, result_dir_path, new_sheet, sheet_name)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m     37\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[1;32m---> 39\u001b[0m \u001b[43mworkbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult_dir_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\workbook\\workbook.py:386\u001b[0m, in \u001b[0;36mWorkbook.save\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworksheets:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_sheet()\n\u001b[1;32m--> 386\u001b[0m \u001b[43msave_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:294\u001b[0m, in \u001b[0;36msave_workbook\u001b[1;34m(workbook, filename)\u001b[0m\n\u001b[0;32m    292\u001b[0m workbook\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mmodified \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(tz\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtimezone\u001b[38;5;241m.\u001b[39mutc)\u001b[38;5;241m.\u001b[39mreplace(tzinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    293\u001b[0m writer \u001b[38;5;241m=\u001b[39m ExcelWriter(workbook, archive)\n\u001b[1;32m--> 294\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:275\u001b[0m, in \u001b[0;36mExcelWriter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write data into the archive.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_archive\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:77\u001b[0m, in \u001b[0;36mExcelWriter.write_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m     custom_override \u001b[38;5;241m=\u001b[39m CustomOverride()\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanifest\u001b[38;5;241m.\u001b[39mappend(custom_override)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_worksheets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_chartsheets()\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_images()\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:215\u001b[0m, in \u001b[0;36mExcelWriter._write_worksheets\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, ws \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkbook\u001b[38;5;241m.\u001b[39mworksheets, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    214\u001b[0m     ws\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_worksheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ws\u001b[38;5;241m.\u001b[39m_drawing:\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_drawing(ws\u001b[38;5;241m.\u001b[39m_drawing)\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:200\u001b[0m, in \u001b[0;36mExcelWriter.write_worksheet\u001b[1;34m(self, ws)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     writer \u001b[38;5;241m=\u001b[39m WorksheetWriter(ws)\n\u001b[1;32m--> 200\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m ws\u001b[38;5;241m.\u001b[39m_rels \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39m_rels\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_archive\u001b[38;5;241m.\u001b[39mwrite(writer\u001b[38;5;241m.\u001b[39mout, ws\u001b[38;5;241m.\u001b[39mpath[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:361\u001b[0m, in \u001b[0;36mWorksheetWriter.write\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_rows()\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_tail()\n\u001b[1;32m--> 361\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:369\u001b[0m, in \u001b[0;36mWorksheetWriter.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03mClose the context manager\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxf:\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:289\u001b[0m, in \u001b[0;36mWorksheetWriter.get_stream\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m xmlfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout) \u001b[38;5;28;01mas\u001b[39;00m xf:\n\u001b[1;32m--> 289\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworksheet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxmlns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSHEET_MAIN_NS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\et_xmlfile\\xmlfile.py:50\u001b[0m, in \u001b[0;36m_FakeIncrementalFileWriter.element\u001b[1;34m(self, tag, attrib, nsmap, **_extra)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_top_element \u001b[38;5;241m=\u001b[39m parent\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_top_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\et_xmlfile\\xmlfile.py:78\u001b[0m, in \u001b[0;36m_FakeIncrementalFileWriter._write_element\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_element\u001b[39m(\u001b[38;5;28mself\u001b[39m, element):\n\u001b[0;32m     77\u001b[0m     xml \u001b[38;5;241m=\u001b[39m tostring(element)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize variables to track the best parameters\n",
    "best_params = None\n",
    "best_result = None\n",
    "\n",
    "# results param\n",
    "best_mse = float(\"inf\")\n",
    "best_avg_acc = float(-1)\n",
    "best_mae = float(\"inf\")\n",
    "\n",
    "# result params tuple\n",
    "best_avg_acc_params = None\n",
    "best_mae_params = None\n",
    "\n",
    "\n",
    "# control sheet style of excel written\n",
    "first_write = True\n",
    "\n",
    "\n",
    "# Evaluate each parameter combination\n",
    "for params in parameter_combinations:\n",
    "\n",
    "    # split dataset to train dataset and test dataset for every params group\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=None\n",
    "    )\n",
    "    results_tuple = evaluate_model(params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    filtered_results = {\n",
    "        k: v for k, v in results_tuple.items() if k != \"model\" and k != \"data_list\"\n",
    "    }\n",
    "\n",
    "    # update best model\n",
    "    if results_tuple['mse'] < best_mse:\n",
    "        best_mse = results_tuple[\"mse\"]\n",
    "        best_params = params\n",
    "        best_model = results_tuple[\"model\"]\n",
    "        best_result = filtered_results\n",
    "\n",
    "    # write result into excel file\n",
    "    sheet_style = [\"num\", \"jobs\", \"X_test\", \"prediction\", \"difference\", \"accuracy\"]\n",
    "    avg_acc = results_tuple[\"avg_acc\"]\n",
    "    data_list = results_tuple['data_list']\n",
    "\n",
    "    if best_avg_acc < results_tuple['avg_acc']:\n",
    "        best_avg_acc = results_tuple[\"avg_acc\"]\n",
    "        best_acc_params = params\n",
    "\n",
    "    if best_mae > results_tuple['mae']:\n",
    "        best_mae = results_tuple[\"mae\"]\n",
    "        best_mae_params = params\n",
    "\n",
    "    if first_write:\n",
    "        # sheet 1\n",
    "        to_excel(\n",
    "            data=data_list,\n",
    "            filename=result_output_filename,\n",
    "            sheet_style=sheet_style,\n",
    "            result_dir_path=result_dir_path,\n",
    "            new_sheet=False,\n",
    "        )\n",
    "        first_write = False\n",
    "    else:\n",
    "        to_excel(\n",
    "            data=data_list,\n",
    "            filename=result_output_filename,\n",
    "            sheet_style=None,\n",
    "            result_dir_path=result_dir_path,\n",
    "            new_sheet=False,\n",
    "        )\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best MSE:\", best_mse)\n",
    "print(\"Best MAE:\", best_result[\"mae\"])\n",
    "print(\"Average:\", best_result[\"avg\"])\n",
    "print(\"Average accuracy:\", best_result[\"avg_acc\"])\n",
    "print(\"Results saved finished.\")\n",
    "\n",
    "params_keys_list = list(best_params.keys())\n",
    "params_values_list = list(best_params.values())\n",
    "\n",
    "# best mse params\n",
    "to_excel(\n",
    "    data=[params_values_list],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=params_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best mse params\",\n",
    ")\n",
    "\n",
    "\n",
    "result_keys_list = list(filtered_results.keys())\n",
    "\n",
    "# avg_acc sheet\n",
    "to_excel(\n",
    "    data=[list(best_acc_params.values())],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=result_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best avg acc params\",\n",
    ")\n",
    "\n",
    "\n",
    "# mae sheet\n",
    "to_excel(\n",
    "    data=[list(best_mae_params.values())],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=result_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best mae params\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# model_file = \"xboost_tasks_time\" + \".json\"\n",
    "# model_path = str(Path.cwd() / \"modelsfile\" / model_file)\n",
    "# best_model.save_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
