{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openpyxl import Workbook, load_workbook  # type: ignore\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def to_excel(\n",
    "    data, filename, sheet_style, result_dir_path, new_sheet=False, sheet_name=\"Sheet1\"\n",
    "):\n",
    "\n",
    "    if not os.path.exists(result_dir_path):\n",
    "        os.makedirs(result_dir_path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(result_dir_path, f\"{filename}.xlsx\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        workbook = load_workbook(file_path)\n",
    "        if new_sheet:\n",
    "            sheet = workbook.create_sheet(title=sheet_name)\n",
    "\n",
    "        else:\n",
    "            sheet = workbook.active\n",
    "    else:\n",
    "        workbook = Workbook()\n",
    "        default_sheet = workbook.active\n",
    "        workbook.remove(default_sheet)\n",
    "        sheet = workbook.create_sheet(title=sheet_name)\n",
    "        \n",
    "    if sheet_style:\n",
    "        sheet.append(sheet_style)\n",
    "\n",
    "\n",
    "    if new_sheet:\n",
    "        print(data)\n",
    "    # write data into file\n",
    "    for row in data:\n",
    "        sheet.append(row)\n",
    "\n",
    "    workbook.save(filename=f\"{result_dir_path}\\\\{filename}.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# read input dataset\n",
    "filename_prefix = (\n",
    "    \"RandomRequestNumberclientv_single_worker_node#loops3#requests_batch150#Thu-Aug-22-20-43-55-2024\"\n",
    ")\n",
    "\n",
    "\n",
    "dataset_read_filename = filename_prefix\n",
    "training_data_dir = Path.cwd().parent / \"training_data\" / \"data_set8\"\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "file_path = f\"{training_data_dir}\\\\{dataset_read_filename}.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "# set result output filename and path\n",
    "result_suffix = \"result\"\n",
    "\n",
    "result_dir_path = Path.cwd().parent / \"results\" / \"result_processTime_waitTasks_v3\"\n",
    "\n",
    "if not os.path.exists(result_dir_path):\n",
    "    os.makedirs(result_dir_path)\n",
    "\n",
    "version_index = len([_ for _ in Path(result_dir_path).iterdir() if _.is_file()])\n",
    "version = f\"_v{version_index}\"\n",
    "\n",
    "result_name = \"processTime#waitTasks\" + version\n",
    "result_output_filename = f\"{filename_prefix}{result_name}{result_suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_excel(filename)\n",
    "    columns = df.columns.to_list()\n",
    "    data_dict = {col: df[col].to_list() for col in columns}\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def data_preprocess(filepath):\n",
    "    data = read_data(filepath)\n",
    "    # TODO more...\n",
    "\n",
    "    # to numpy\n",
    "    for key in data.keys():\n",
    "        data[key] = np.array(data[key])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_preprocess(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Style View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset is a dictionary\n",
    "\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "import cupy as cp\n",
    "\n",
    "y = cp.array(dataset.get(\"processed_and_waited_time_on_manager_node\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strandard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler       # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "_X = [dataset.get(\"request_num\"), dataset.get(\"sub_processing_tasks_on_manager_node\"), dataset.get(\"processed_time_on_worker_node\")]\n",
    "\n",
    "for i in range(len(_X)):\n",
    "    _X[i] = np.array(_X[i]).reshape(-1, 1)\n",
    "    \n",
    "\n",
    "_scaler = \"normalization\"\n",
    "\n",
    "if _scaler == \"standard\":\n",
    "    X_scaler = StandardScaler()\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "elif _scaler == \"normalization\":\n",
    "    X_scaler = MinMaxScaler()\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "elif _scaler == \"log\":\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = np.log1p(_X[i])\n",
    "elif _scaler == \"power\":\n",
    "    X_scaler = PowerTransformer(method='yeo-johnson')\n",
    "    for i in range(len(_X)):\n",
    "        _X[i] = X_scaler.fit_transform(_X[i])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "for i in range(len(_X)):\n",
    "    _X[i] = _X[i].reshape(-1)\n",
    "\n",
    "X = cp.asarray(np.array(\n",
    "    _X\n",
    ").T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter combinations: 3120\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the parameter ranges\n",
    "params = {\n",
    "    \"max_depth\": [5],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"n_estimators\": [i for i in range(100, 4000, 100)],\n",
    "    \"min_child_weight\": [1],\n",
    "    \"subsample\": [0.1],\n",
    "    \"colsample_bytree\": [0.1],\n",
    "    \"reg_alpha\": [0, 0.1],\n",
    "    \"reg_lambda\": [i / 10 for i in range(10, 50, 1)],\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     \"max_depth\": [3],\n",
    "#     \"learning_rate\": [0.01],\n",
    "#     \"n_estimators\": [3800],\n",
    "#     \"min_child_weight\": [1],\n",
    "#     \"subsample\": [0.1],\n",
    "#     \"colsample_bytree\": [0.1],\n",
    "#     \"reg_alpha\": [0],\n",
    "#     \"reg_lambda\": [3.6],\n",
    "# }\n",
    "\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "parameter_combinations = [\n",
    "    dict(zip(params.keys(), combination))\n",
    "    for combination in itertools.product(*params.values())\n",
    "]\n",
    "\n",
    "# Print the number of parameter combinations and a few examples\n",
    "print(f\"Number of parameter combinations: {len(parameter_combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor  # type: ignore\n",
    "import xgboost  # type: ignore\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # type: ignore\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# Create the XGBoost regressor model\n",
    "def create_model(params):\n",
    "    # if use gpu to add these two params\n",
    "    # - tree_method=\"hist\",\n",
    "    # - device=\"cuda\",\n",
    "    \n",
    "    return XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        subsample=params[\"subsample\"],\n",
    "        colsample_bytree=params[\"colsample_bytree\"],\n",
    "        reg_alpha=params[\"reg_alpha\"],\n",
    "        reg_lambda=params[\"reg_lambda\"],\n",
    "        device=\"cuda\",\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(\n",
    "    params, X_train, y_train, X_test: np.array, y_test: np.array\n",
    ") -> Tuple[np.float64, xgboost.Booster]:\n",
    "\n",
    "    model = create_model(params)\n",
    "\n",
    "    # Convert CuPy arrays to NumPy arrays\n",
    "\n",
    "    model.fit(X_train, y_train, verbose=True)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # typecasting  cp -> np\n",
    "    y_test_np = cp.asnumpy(y_test)\n",
    "    X_test_np = cp.asnumpy(X_test)\n",
    "    predictions_np = cp.asnumpy(predictions)\n",
    "\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = float(mean_squared_error(y_test_np, predictions_np))\n",
    "    mae = float(mean_absolute_error(y_test_np, predictions_np))\n",
    "    avg = float(np.mean(y_test_np))\n",
    "    avg_acc = 100 * (avg - mae) / avg\n",
    "\n",
    "    # calculate diffirence and accuracy\n",
    "    data_list = list()\n",
    "    for i in range(len(y_test_np)):\n",
    "        acc = 0\n",
    "        diff = abs(y_test_np[i] - predictions_np[i])\n",
    "        if predictions[i] < 0:\n",
    "            acc = 0\n",
    "        else:\n",
    "            rate = diff / y_test_np[i]\n",
    "            if rate < 1 and rate >= 0:\n",
    "                acc = 1 - rate\n",
    "            if rate > 1:\n",
    "                acc = 0\n",
    "        data_list.append(\n",
    "            [\n",
    "                float(X_test_np[i][0]),\n",
    "                float(X_test_np[i][1]),\n",
    "                float(X_test_np[i][2]),\n",
    "                float(y_test_np[i]),\n",
    "                float(predictions_np[i]),\n",
    "                float(diff),\n",
    "                float(round(acc, 5)),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    results_tuple = {\"mse\": mse, \"mae\": mae, \"avg\": avg, \"avg_acc\": avg_acc, \"model\": model, \"data_list\": data_list}\n",
    "    filtered_results = {k: v for k, v in results_tuple.items() if k != \"model\" and k != \"data_list\"}\n",
    "    print(filtered_results, f'\\n{params}', '\\n')\n",
    "    return results_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 718.0167216935415, 'mae': 23.329663565423754, 'avg': 46.45586587323083, 'avg_acc': 49.78101661244256} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.0} \n",
      "\n",
      "Best acc 49.78101661244256\n",
      "{'mse': 629.2455158572657, 'mae': 21.82968061765035, 'avg': 40.82756203545465, 'avg_acc': 46.53200061592348} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.1} \n",
      "\n",
      "Best acc 49.78101661244256\n",
      "{'mse': 769.1835293595933, 'mae': 24.20462843047248, 'avg': 49.50597881211175, 'avg_acc': 51.10766616223178} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.2} \n",
      "\n",
      "Best acc 51.10766616223178\n",
      "{'mse': 912.9149254163663, 'mae': 27.042403973473444, 'avg': 46.654923322465685, 'avg_acc': 42.03740559905336} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.3} \n",
      "\n",
      "Best acc 51.10766616223178\n",
      "{'mse': 646.1092641082965, 'mae': 21.787287171681722, 'avg': 42.26081324153476, 'avg_acc': 48.44565094580635} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.4} \n",
      "\n",
      "Best acc 51.10766616223178\n",
      "{'mse': 714.3489634187218, 'mae': 23.707457113265992, 'avg': 45.90085793071323, 'avg_acc': 48.35073202977578} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.5} \n",
      "\n",
      "Best acc 51.10766616223178\n",
      "{'mse': 708.2912236568861, 'mae': 23.33959962526957, 'avg': 43.87978442509969, 'avg_acc': 46.8101315194268} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.6} \n",
      "\n",
      "Best acc 51.10766616223178\n",
      "{'mse': 633.6147982920297, 'mae': 21.160839229159883, 'avg': 46.624862347708806, 'avg_acc': 54.61468803628597} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.7} \n",
      "\n",
      "Best acc 54.61468803628597\n",
      "{'mse': 658.7521425542113, 'mae': 21.75638456609514, 'avg': 48.64608531792958, 'avg_acc': 55.27618630789116} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.8} \n",
      "\n",
      "Best acc 55.27618630789116\n",
      "{'mse': 734.2033250166561, 'mae': 23.200066661834718, 'avg': 46.391161632537845, 'avg_acc': 49.99033038749637} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 1.9} \n",
      "\n",
      "Best acc 55.27618630789116\n",
      "{'mse': 629.9399792303918, 'mae': 21.426308827930026, 'avg': 41.408716932932535, 'avg_acc': 48.25652564257651} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.0} \n",
      "\n",
      "Best acc 55.27618630789116\n",
      "{'mse': 730.4460270783276, 'mae': 22.650526735517715, 'avg': 49.230740722020464, 'avg_acc': 53.99109092545841} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.1} \n",
      "\n",
      "Best acc 55.27618630789116\n",
      "{'mse': 798.1592265995704, 'mae': 24.232636989487542, 'avg': 46.38015535407596, 'avg_acc': 47.75214355258096} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.2} \n",
      "\n",
      "Best acc 55.27618630789116\n",
      "{'mse': 609.7285654150787, 'mae': 20.40150288210975, 'avg': 47.62357176939646, 'avg_acc': 57.160913967355924} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.3} \n",
      "\n",
      "Best acc 57.160913967355924\n",
      "{'mse': 826.6190036035046, 'mae': 25.203366724650063, 'avg': 45.62997159428067, 'avg_acc': 44.7657628438912} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.4} \n",
      "\n",
      "Best acc 57.160913967355924\n",
      "{'mse': 598.1222490097683, 'mae': 21.020451437102423, 'avg': 46.874627725283304, 'avg_acc': 55.15601412282922} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.5} \n",
      "\n",
      "Best acc 57.160913967355924\n",
      "{'mse': 724.1966576887074, 'mae': 23.31612810558743, 'avg': 45.55086047384474, 'avg_acc': 48.81297990193724} \n",
      "{'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.1, 'colsample_bytree': 0.1, 'reg_alpha': 0, 'reg_lambda': 2.6} \n",
      "\n",
      "Best acc 57.160913967355924\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m parameter_combinations:\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# split dataset to train dataset and test dataset for every params group\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     25\u001b[0m         X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     )\n\u001b[1;32m---> 27\u001b[0m     results_tuple \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     filtered_results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results_tuple\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_list\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m     }\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# update best model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(params, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(params)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Convert CuPy arrays to NumPy arrays\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Make predictions using the trained model\u001b[39;00m\n\u001b[0;32m     39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1108\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m-> 1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Public\\Soar\\github\\.venv\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize variables to track the best parameters\n",
    "best_params = None\n",
    "best_result = None\n",
    "\n",
    "# results param\n",
    "best_mse = float(\"inf\")\n",
    "best_avg_acc = float(-1)\n",
    "best_mae = float(\"inf\")\n",
    "\n",
    "# result params tuple\n",
    "best_avg_acc_params = None\n",
    "best_mae_params = None\n",
    "\n",
    "\n",
    "# control sheet style of excel written\n",
    "first_write = True\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate each parameter combination\n",
    "for params in parameter_combinations:\n",
    "\n",
    "    # split dataset to train dataset and test dataset for every params group\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=None\n",
    "    )\n",
    "    results_tuple = evaluate_model(params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    filtered_results = {\n",
    "        k: v for k, v in results_tuple.items() if k != \"model\" and k != \"data_list\"\n",
    "    }\n",
    "\n",
    "    # update best model\n",
    "    if results_tuple['mse'] < best_mse:\n",
    "        best_mse = results_tuple[\"mse\"]\n",
    "        best_params = params\n",
    "        best_model = results_tuple[\"model\"]\n",
    "        best_result = filtered_results\n",
    "\n",
    "    # write result into excel file\n",
    "    sheet_style = [\"num\", \"jobs\", \"X_test\", \"prediction\", \"difference\", \"accuracy\"]\n",
    "    avg_acc = results_tuple[\"avg_acc\"]\n",
    "    data_list = results_tuple['data_list']\n",
    "\n",
    "    if best_avg_acc < results_tuple['avg_acc']:\n",
    "        best_avg_acc = results_tuple[\"avg_acc\"]\n",
    "        best_acc_params = params\n",
    "\n",
    "    if best_mae > results_tuple['mae']:\n",
    "        best_mae = results_tuple[\"mae\"]\n",
    "        best_mae_params = params\n",
    "\n",
    "    if first_write:\n",
    "        # sheet 1\n",
    "        to_excel(\n",
    "            data=data_list,\n",
    "            filename=result_output_filename,\n",
    "            sheet_style=sheet_style,\n",
    "            result_dir_path=result_dir_path,\n",
    "            new_sheet=False,\n",
    "        )\n",
    "        first_write = False\n",
    "    else:\n",
    "        to_excel(\n",
    "            data=data_list,\n",
    "            filename=result_output_filename,\n",
    "            sheet_style=None,\n",
    "            result_dir_path=result_dir_path,\n",
    "            new_sheet=False,\n",
    "        )\n",
    "    print(f\"Best acc {best_avg_acc}\")\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best MSE:\", best_mse)\n",
    "print(\"Best MAE:\", best_result[\"mae\"])\n",
    "print(\"Average:\", best_result[\"avg\"])\n",
    "print(\"Average accuracy:\", best_result[\"avg_acc\"])\n",
    "print(\"Results saved finished.\")\n",
    "\n",
    "params_keys_list = list(best_params.keys())\n",
    "params_values_list = list(best_params.values())\n",
    "\n",
    "# best mse params\n",
    "to_excel(\n",
    "    data=[params_values_list],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=params_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best mse params\",\n",
    ")\n",
    "\n",
    "\n",
    "result_keys_list = list(filtered_results.keys())\n",
    "\n",
    "# avg_acc sheet\n",
    "to_excel(\n",
    "    data=[list(best_acc_params.values())],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=result_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best avg acc params\",\n",
    ")\n",
    "\n",
    "\n",
    "# mae sheet\n",
    "to_excel(\n",
    "    data=[list(best_mae_params.values())],\n",
    "    filename=result_output_filename,\n",
    "    sheet_style=result_keys_list,\n",
    "    result_dir_path=result_dir_path,\n",
    "    new_sheet=True,\n",
    "    sheet_name=\"best mae params\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# model_file = \"xboost_tasks_time\" + \".json\"\n",
    "# model_path = str(Path.cwd() / \"modelsfile\" / model_file)\n",
    "# best_model.save_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
